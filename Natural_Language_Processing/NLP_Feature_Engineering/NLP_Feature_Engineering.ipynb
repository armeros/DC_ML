{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOumg0CG-OiX",
        "outputId": "199c698b-030b-4f3c-9418-de59bb799f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textatistic\n",
            "  Downloading textatistic-0.0.1.tar.gz (29 kB)\n",
            "Collecting pyhyphen>=2.0.5\n",
            "  Downloading PyHyphen-4.0.3.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.36.0 in /usr/local/lib/python3.8/dist-packages (from pyhyphen>=2.0.5->textatistic) (0.38.4)\n",
            "Requirement already satisfied: setuptools>=52.0 in /usr/local/lib/python3.8/dist-packages (from pyhyphen>=2.0.5->textatistic) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pyhyphen>=2.0.5->textatistic) (1.4.4)\n",
            "Collecting requests>=2.25\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2022.12.7)\n",
            "Building wheels for collected packages: textatistic, pyhyphen\n",
            "  Building wheel for textatistic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textatistic: filename=textatistic-0.0.1-py3-none-any.whl size=29068 sha256=6d68ddb4613deff4301913261569108ddd9fc28e26606d92709ad6b910d7a034\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/24/c4/de7882083c3530984f6eda43ae9e94875c84d906063ef10bcb\n",
            "  Building wheel for pyhyphen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyhyphen: filename=PyHyphen-4.0.3-cp37-abi3-linux_x86_64.whl size=61050 sha256=1021e80e178a0e7c588040baab82a16cd5c5fc0ee5901c4b5bdd78daee9a5ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/10/17/b7d8ccc1f884ac699f7bdd1f4bd916d4ef111812a5d3177ff9\n",
            "Successfully built textatistic pyhyphen\n",
            "Installing collected packages: requests, pyhyphen, textatistic\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed pyhyphen-4.0.3 requests-2.28.1 textatistic-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, contourpy, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed contourpy-1.0.6 fonttools-4.38.0 matplotlib-3.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install textatistic\n",
        "!pip install matplotlib --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt, numpy as np, seaborn as sns, pandas as pd, re, nltk, itertools, spacy\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"vader_lexicon\")\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize, TweetTokenizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tree import Tree\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "from collections import Counter, defaultdict\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_lg\n",
        "from spacy.lang.en import English\n",
        "from spacy.matcher import PhraseMatcher, Matcher\n",
        "from spacy.tokens import Doc, Span\n",
        "from spacy.language import Language\n",
        "from spacy.pipeline import EntityRuler\n",
        "from textatistic import Textatistic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZqoia9J-Uyn",
        "outputId": "119f82a6-7624-4cdc-d38d-b692fbf7309d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-19 16:32:14.374314: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-19 16:32:25.621096: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.8 MB 234 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-md==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.28.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-19 16:32:39.206731: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 587.7 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.28.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***One-hot encoding***\n",
        "\n",
        "Convert `df1` into a format that is suitable for machine learning.\n",
        "\n",
        "- Use the **`columns`** attribute to print the features of `df1`.\n",
        "- Use the **`pd.get_dummies()`** function to perform one-hot encoding on `feature 5` of `df1`.\n",
        "- Use the **`columns`** attribute again to print the new features of `df1`.\n",
        "- Print the first five rows of df1 using **`head()`**.\n",
        "\n",
        "\n",
        "```\n",
        "   feature 1  feature 2  feature 3  feature 4 feature 5  label\n",
        "0     29.000          0          0    211.338    female      1\n",
        "1      0.917          1          2    151.550      male      1\n",
        "2      2.000          1          2    151.550    female      0\n",
        "3     30.000          1          2    151.550      male      0\n",
        "4     25.000          1          2    151.550    female      0\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OyrQrZCyFtEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the features of df1\n",
        "print(df1.columns)\n",
        "\n",
        "# Perform one-hot encoding\n",
        "df1 = pd.get_dummies(df1, columns=['feature 5'])\n",
        "\n",
        "# Print the new features of df1\n",
        "print(df1.columns)\n",
        "\n",
        "# Print first five rows of df1\n",
        "print(df1.head())\n",
        "\n",
        "df1 = pd.get_dummies(df1, columns=['feature 5'], drop_first=True)\n",
        "print(df1.head())"
      ],
      "metadata": {
        "id": "z4Byn2ow-n-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    Index(['feature 1', 'feature 2', 'feature 3', 'feature 4', 'feature 5', 'label'], dtype='object')\n",
        "\n",
        "    Index(['feature 1', 'feature 2', 'feature 3', 'feature 4', 'label', 'feature 5_female', 'feature 5_male'], dtype='object')\n",
        "\n",
        "       feature 1  feature 2  feature 3  feature 4  label  feature 5_female  feature 5_male\n",
        "    0     29.000          0          0    211.338      1                 1               0\n",
        "    1      0.917          1          2    151.550      1                 0               1\n",
        "    2      2.000          1          2    151.550      0                 1               0\n",
        "    3     30.000          1          2    151.550      0                 0               1\n",
        "    4     25.000          1          2    151.550      0                 1               0\n",
        "\n",
        "\n",
        "        feature 1  feature 2  feature 3  feature 4  label  feature 5_male\n",
        "    0     29.000          0          0    211.338      1               0\n",
        "    1      0.917          1          2    151.550      1               1\n",
        "    2      2.000          1          2    151.550      0               0\n",
        "    3     30.000          1          2    151.550      0               1\n",
        "    4     25.000          1          2    151.550      0               0\n",
        "```\n",
        "## ***Character count of Russian tweets***\n",
        "\n",
        "In this exercise, you have been given a dataframe tweets which contains some tweets associated with Russia's Internet Research Agency and compiled by FiveThirtyEight.\n",
        "\n",
        "Create a new feature `'char_count'` in `tweets` which computes the number of characters for each tweet. Also, compute the average length of each tweet. The tweets are available in the `content` feature of `tweets`.\n",
        "\n",
        "\n",
        "- Create a new feature `char_count` by applying **`len`** to the `'content'` feature of `tweets`.\n",
        "\n",
        "- Print the average character count of the tweets by computing the mean of the `'char_count'` feature.\n"
      ],
      "metadata": {
        "id": "1zBl6iWtGjSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv('russian_tweets.csv')\n",
        "\n",
        "# Create a feature char_count\n",
        "tweets['char_count'] = tweets['content'].apply(len)\n",
        "\n",
        "# Print the average character count\n",
        "print(tweets['char_count'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzPa9lGgGqLC",
        "outputId": "2446d241-f1fa-4aeb-8fc5-15cce7524f4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103.462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the average character count of these tweets is approximately 104, which is much higher than the overall average tweet length of around 40 characters. Depending on what you're working on, this may be something worth investigating into. For your information, there is research that indicates that fake news articles tend to have longer titles! Therefore, even extremely basic features such as character counts can prove to be very useful in certain applications.\n",
        "\n",
        "## ***Word count of TED talks***\n",
        "\n",
        "`ted` is a dataframe that contains the transcripts of 500 TED talks. Your job is to compute a new feature `word_count` which contains the approximate number of words for each talk. Consequently, you also need to compute the average word count of the talks. The transcripts are available as the `transcript` feature in `ted`.\n",
        "\n",
        "In order to complete this task, you will need to define a function `count_words` that takes in a string as an argument and returns the number of words in the string. You will then need to apply this function to the `transcript` feature of ted to create the new feature `word_count` and compute its mean.\n",
        "\n",
        "- Split string into a list of words using the **`split()`** method.\n",
        "- Return the number of elements in words using `len()`.\n",
        "- Apply your function to the `transcript` column of `ted` to create the new feature `word_count`.\n",
        "- Compute the average word count of the talks using **`mean()`**."
      ],
      "metadata": {
        "id": "Ten7Jh4FKFUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ted = pd.read_csv('ted.csv')\n",
        "\n",
        "# Function that returns number of words in a string\n",
        "def count_words(string):\n",
        "\t  # Split the string into words\n",
        "    words = string.split()\n",
        "    \n",
        "    # Return the number of words\n",
        "    return len(words)\n",
        "\n",
        "# Create a new feature word_count\n",
        "ted['word_count'] = ted['transcript'].apply(count_words)\n",
        "\n",
        "# Print the average word count of the talks\n",
        "print(ted['word_count'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZJYrcRCJ6QU",
        "outputId": "e9527b4a-5be8-43f9-d926-60791987e352"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1987.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the `word_count` feature to compute its correlation with other variables such as number of views, number of comments, etc. and derive extremely interesting insights about TED.\n",
        "\n",
        "## ***Hashtags and mentions in Russian tweets***\n",
        "\n",
        "Let's revisit the `tweets` dataframe containing the Russian tweets. In this exercise, you will compute the number of hashtags and mentions in each tweet by defining two functions `count_hashtags()` and `count_mentions()` respectively and applying them to the `content` feature of tweets.\n",
        "\n",
        "In case you don't recall, the `tweets` are contained in the `content` feature of `tweets`.\n",
        "\n",
        "\n",
        "- In the list comprehension, use **`startswith()`** to check if a particular word starts with `'#'`.\n",
        "\n",
        "- In the list comprehension, use **`startswith()`** to check if a particular word starts with `'@'`."
      ],
      "metadata": {
        "id": "3mUXD5GALin1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns numner of hashtags in a string\n",
        "def count_hashtags(string):\n",
        "\t# Split the string into words\n",
        "    words = string.split()\n",
        "    \n",
        "    # Create a list of words that are hashtags\n",
        "    hashtags = [word for word in words if word.startswith('#')]\n",
        "    \n",
        "    # Return number of hashtags\n",
        "    return(len(hashtags))\n",
        "\n",
        "# Create a feature hashtag_count and display distribution\n",
        "tweets['hashtag_count'] = tweets['content'].apply(count_hashtags)\n",
        "tweets['hashtag_count'].hist()\n",
        "plt.title('Hashtag count distribution')\n",
        "plt.show()\n",
        "\n",
        "# Function that returns number of mentions in a string\n",
        "def count_mentions(string):\n",
        "\t# Split the string into words\n",
        "    words = string.split()\n",
        "    \n",
        "    # Create a list of words that are mentions\n",
        "    mentions = [word for word in words if word.startswith('@')]\n",
        "    \n",
        "    # Return number of mentions\n",
        "    return(len(mentions))\n",
        "\n",
        "# Create a feature mention_count and display distribution\n",
        "tweets['mention_count'] = tweets['content'].apply(count_mentions)\n",
        "tweets['mention_count'].hist()\n",
        "plt.title('Mention count distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "mQOWzSnFLAth",
        "outputId": "42b518b2-af0e-4ecf-f846-e5ae07d9323e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Readability of 'The Myth of Sisyphus'***\n",
        "\n",
        "Compute the Flesch reading ease score for Albert Camus' famous essay The Myth of Sisyphus. We will then interpret the value of this score as explained in the video and try to determine the reading level of the essay.\n",
        "\n",
        "The entire essay is in the form of a string and is available as `sisyphus_essay`.\n",
        "\n",
        "- Import the **`Textatistic`** class from `textatistic`.\n",
        "- Compute the **`readability_scores`** dictionary for `sisyphus_essay` using **`Textatistic`**.\n",
        "- Print the Flesch reading ease score from the `readability_scores` dictionary."
      ],
      "metadata": {
        "id": "9dPFQMP0jFnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sisyphus_essay = '\\nThe gods had condemned Sisyphus to ceaselessly rolling a rock to the top of a mountain, whence the stone would fall back of its own weight. They had thought with some reason that there is no more dreadful punishment than futile and hopeless labor. If one believes Homer, Sisyphus was the wisest and most prudent of mortals. According to another tradition, however, he was disposed to practice the profession of highwayman. I see no contradiction in this. Opinions differ as to the reasons why he became the futile laborer of the underworld. To begin with, he is accused of a certain levity in regard to the gods. He stole their secrets. Egina, the daughter of Esopus, was carried off by Jupiter. The father was shocked by that disappearance and complained to Sisyphus. He, who knew of the abduction, offered to tell about it on condition that Esopus would give water to the citadel of Corinth. To the celestial thunderbolts he preferred the benediction of water. He was punished for this in the underworld. Homer tells us also that Sisyphus had put Death in chains. Pluto could not endure the sight of his deserted, silent empire. He dispatched the god of war, who liberated Death from the hands of her conqueror. It is said that Sisyphus, being near to death, rashly wanted to test his wife\\'s love. He ordered her to cast his unburied body into the middle of the public square. Sisyphus woke up in the underworld. And there, annoyed by an obedience so contrary to human love, he obtained from Pluto permission to return to earth in order to chastise his wife. But when he had seen again the face of this world, enjoyed water and sun, warm stones and the sea, he no longer wanted to go back to the infernal darkness. Recalls, signs of anger, warnings were of no avail. Many years more he lived facing the curve of the gulf, the sparkling sea, and the smiles of earth. A decree of the gods was necessary. Mercury came and seized the impudent man by the collar and, snatching him from his joys, lead him forcibly back to the underworld, where his rock was ready for him. You have already grasped that Sisyphus is the absurd hero. He is, as much through his passions as through his torture. His scorn of the gods, his hatred of death, and his passion for life won him that unspeakable penalty in which the whole being is exerted toward accomplishing nothing. This is the price that must be paid for the passions of this earth. Nothing is told us about Sisyphus in the underworld. Myths are made for the imagination to breathe life into them. As for this myth, one sees merely the whole effort of a body straining to raise the huge stone, to roll it, and push it up a slope a hundred times over; one sees the face screwed up, the cheek tight against the stone, the shoulder bracing the clay-covered mass, the foot wedging it, the fresh start with arms outstretched, the wholly human security of two earth-clotted hands. At the very end of his long effort measured by skyless space and time without depth, the purpose is achieved. Then Sisyphus watches the stone rush down in a few moments toward tlower world whence he will have to push it up again toward the summit. He goes back down to the plain. It is during that return, that pause, that Sisyphus interests me. A face that toils so close to stones is already stone itself! I see that man going back down with a heavy yet measured step toward the torment of which he will never know the end. That hour like a breathing-space which returns as surely as his suffering, that is the hour of consciousness. At each of those moments when he leaves the heights and gradually sinks toward the lairs of the gods, he is superior to his fate. He is stronger than his rock. If this myth is tragic, that is because its hero is conscious. Where would his torture be, indeed, if at every step the hope of succeeding upheld him? The workman of today works everyday in his life at the same tasks, and his fate is no less absurd. But it is tragic only at the rare moments when it becomes conscious. Sisyphus, proletarian of the gods, powerless and rebellious, knows the whole extent of his wretched condition: it is what he thinks of during his descent. The lucidity that was to constitute his torture at the same time crowns his victory. There is no fate that can not be surmounted by scorn. If the descent is thus sometimes performed in sorrow, it can also take place in joy. This word is not too much. Again I fancy Sisyphus returning toward his rock, and the sorrow was in the beginning. When the images of earth cling too tightly to memory, when the call of happiness becomes too insistent, it happens that melancholy arises in man\\'s heart: this is the rock\\'s victory, this is the rock itself. The boundless grief is too heavy to bear. These are our nights of Gethsemane. But crushing truths perish from being acknowledged. Thus, Edipus at the outset obeys fate without knowing it. But from the moment he knows, his tragedy begins. Yet at the same moment, blind and desperate, he realizes that the only bond linking him to the world is the cool hand of a girl. Then a tremendous remark rings out: \"Despite so many ordeals, my advanced age and the nobility of my soul make me conclude that all is well.\" Sophocles\\' Edipus, like Dostoevsky\\'s Kirilov, thus gives the recipe for the absurd victory. Ancient wisdom confirms modern heroism. One does not discover the absurd without being tempted to write a manual of happiness. \"What!---by such narrow ways--?\" There is but one world, however. Happiness and the absurd are two sons of the same earth. They are inseparable. It would be a mistake to say that happiness necessarily springs from the absurd. Discovery. It happens as well that the felling of the absurd springs from happiness. \"I conclude that all is well,\" says Edipus, and that remark is sacred. It echoes in the wild and limited universe of man. It teaches that all is not, has not been, exhausted. It drives out of this world a god who had come into it with dissatisfaction and a preference for futile suffering. It makes of fate a human matter, which must be settled among men. All Sisyphus\\' silent joy is contained therein. His fate belongs to him. His rock is a thing. Likewise, the absurd man, when he contemplates his torment, silences all the idols. In the universe suddenly restored to its silence, the myriad wondering little voices of the earth rise up. Unconscious, secret calls, invitations from all the faces, they are the necessary reverse and price of victory. There is no sun without shadow, and it is essential to know the night. The absurd man says yes and his efforts will henceforth be unceasing. If there is a personal fate, there is no higher destiny, or at least there is, but one which he concludes is inevitable and despicable. For the rest, he knows himself to be the master of his days. At that subtle moment when man glances backward over his life, Sisyphus returning toward his rock, in that slight pivoting he contemplates that series of unrelated actions which become his fate, created by him, combined under his memory\\'s eye and soon sealed by his death. Thus, convinced of the wholly human origin of all that is human, a blind man eager to see who knows that the night has no end, he is still on the go. The rock is still rolling. I leave Sisyphus at the foot of the mountain! One always finds one\\'s burden again. But Sisyphus teaches the higher fidelity that negates the gods and raises rocks. He too concludes that all is well. This universe henceforth without a master seems to him neither sterile nor futile. Each atom of that stone, each mineral flake of that night filled mountain, in itself forms a world. The struggle itself toward the heights is enough to fill a man\\'s heart. One must imagine Sisyphus happy.\\n'\n",
        "\n",
        "# Import Textatistic\n",
        "from textatistic import Textatistic\n",
        "\n",
        "# Compute the readability scores \n",
        "readability_scores = Textatistic(sisyphus_essay).scores\n",
        "\n",
        "# Print the flesch reading ease score\n",
        "flesch = readability_scores['flesch_score']\n",
        "print(\"The Flesch Reading Ease is %.2f\" % (flesch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B97chqEzP6xF",
        "outputId": "60a502c5-ab09-4dd5-e491-b9ac70f628fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Flesch Reading Ease is 81.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the score for this essay is approximately 81.67. This indicates that the essay is at the readability level of a 6th grade American student.\n",
        "\n",
        "## ***Readability of various publications***\n",
        "\n",
        "In this exercise, you have been given excerpts of articles from four publications. Your task is to compute the readability of these excerpts using the Gunning fog index and consequently, determine the relative difficulty of reading these publications.\n",
        "\n",
        "The excerpts are available as the following strings:\n",
        "\n",
        "- `forbes`- An excerpt from an article from Forbes magazine on the Chinese social credit score system.\n",
        "- `harvard_law`- An excerpt from a book review published in Harvard Law Review.\n",
        "\n",
        "-`r_digest`- An excerpt from a Reader's Digest article on flight turbulence.\n",
        "\n",
        "- `time_kids` - An excerpt from an article on the ill effects of salt consumption published in TIME for Kids.\n",
        "\n",
        "- Import the **`Textatistic`** class from `textatistic`.\n",
        "- Compute the `readability_scores` dictionary for each excerpt using **`Textatistic`**.\n",
        "- Select the Gunning fog index from the `readability_scores` dictionary for each excerpt and append it to `gunning_fog_scores`.\n",
        "- Print the list of Gunning fog indices."
      ],
      "metadata": {
        "id": "xCI1drsVkC8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Textatistic\n",
        "from textatistic import Textatistic\n",
        "\n",
        "# List of excerpts\n",
        "excerpts = [forbes, harvard_law, r_digest, time_kids]\n",
        "\n",
        "# Loop through excerpts and compute gunning fog index\n",
        "gunning_fog_scores = []\n",
        "for excerpt in excerpts:\n",
        "    readability_scores = Textatistic(excerpt).scores\n",
        "    gunning_fog = readability_scores['gunningfog_score']\n",
        "    gunning_fog_scores.append(gunning_fog)\n",
        "\n",
        "# Print the gunning fog indices\n",
        "print(gunning_fog_scores)"
      ],
      "metadata": {
        "id": "WUXvJu2Vj97e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "[14.436002482929858, 20.735401069518716, 11.085587583148559, 5.926785009861934]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You are now adept at computing readability scores for various pieces of text. Notice that the Harvard Law Review excerpt has the highest Gunning fog index; indicating that it can be comprehended only by readers who have graduated college. On the other hand, the Time for Kids article, intended for children, has a much lower fog index and can be comprehended by 5th grade students.\n",
        "\n",
        "## ***Tokenizing the Gettysburg Address***\n",
        "\n",
        "In this exercise, you will be tokenizing one of the most famous speeches of all time: the Gettysburg Address delivered by American President Abraham Lincoln during the American Civil War.\n",
        "\n",
        "The entire speech is available as a string named **`gettysburg`**.\n",
        "\n",
        "- Load the `en_core_web_sm` model using **`spacy.load()`**.\n",
        "- Create a `doc` object `doc` for the `gettysburg` string.\n",
        "- Using list comprehension, loop over `doc` to generate the token texts."
      ],
      "metadata": {
        "id": "vreqcQGAk3Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gettysburg = \"Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal. Now we're engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We're met on a great battlefield of that war. We've come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It's altogether fitting and proper that we should do this. But, in a larger sense, we can't dedicate - we can not consecrate - we can not hallow - this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It's rather for us to be here dedicated to the great task remaining before us - that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion - that we here highly resolve that these dead shall not have died in vain - that this nation, under God, shall have a new birth of freedom - and that government of the people, by the people, for the people, shall not perish from the earth.\"\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the en_core_web_sm model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a Doc object\n",
        "doc = nlp(gettysburg)\n",
        "\n",
        "# Generate the tokens\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atb76oqelCOT",
        "outputId": "5a03c23c-7e3f-4380-bb63-1efe28527e28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Four', 'score', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceived', 'in', 'Liberty', ',', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal', '.', 'Now', 'we', \"'re\", 'engaged', 'in', 'a', 'great', 'civil', 'war', ',', 'testing', 'whether', 'that', 'nation', ',', 'or', 'any', 'nation', 'so', 'conceived', 'and', 'so', 'dedicated', ',', 'can', 'long', 'endure', '.', 'We', \"'re\", 'met', 'on', 'a', 'great', 'battlefield', 'of', 'that', 'war', '.', 'We', \"'ve\", 'come', 'to', 'dedicate', 'a', 'portion', 'of', 'that', 'field', ',', 'as', 'a', 'final', 'resting', 'place', 'for', 'those', 'who', 'here', 'gave', 'their', 'lives', 'that', 'that', 'nation', 'might', 'live', '.', 'It', \"'s\", 'altogether', 'fitting', 'and', 'proper', 'that', 'we', 'should', 'do', 'this', '.', 'But', ',', 'in', 'a', 'larger', 'sense', ',', 'we', 'ca', \"n't\", 'dedicate', '-', 'we', 'can', 'not', 'consecrate', '-', 'we', 'can', 'not', 'hallow', '-', 'this', 'ground', '.', 'The', 'brave', 'men', ',', 'living', 'and', 'dead', ',', 'who', 'struggled', 'here', ',', 'have', 'consecrated', 'it', ',', 'far', 'above', 'our', 'poor', 'power', 'to', 'add', 'or', 'detract', '.', 'The', 'world', 'will', 'little', 'note', ',', 'nor', 'long', 'remember', 'what', 'we', 'say', 'here', ',', 'but', 'it', 'can', 'never', 'forget', 'what', 'they', 'did', 'here', '.', 'It', 'is', 'for', 'us', 'the', 'living', ',', 'rather', ',', 'to', 'be', 'dedicated', 'here', 'to', 'the', 'unfinished', 'work', 'which', 'they', 'who', 'fought', 'here', 'have', 'thus', 'far', 'so', 'nobly', 'advanced', '.', 'It', \"'s\", 'rather', 'for', 'us', 'to', 'be', 'here', 'dedicated', 'to', 'the', 'great', 'task', 'remaining', 'before', 'us', '-', 'that', 'from', 'these', 'honored', 'dead', 'we', 'take', 'increased', 'devotion', 'to', 'that', 'cause', 'for', 'which', 'they', 'gave', 'the', 'last', 'full', 'measure', 'of', 'devotion', '-', 'that', 'we', 'here', 'highly', 'resolve', 'that', 'these', 'dead', 'shall', 'not', 'have', 'died', 'in', 'vain', '-', 'that', 'this', 'nation', ',', 'under', 'God', ',', 'shall', 'have', 'a', 'new', 'birth', 'of', 'freedom', '-', 'and', 'that', 'government', 'of', 'the', 'people', ',', 'by', 'the', 'people', ',', 'for', 'the', 'people', ',', 'shall', 'not', 'perish', 'from', 'the', 'earth', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Lemmatizing the Gettysburg address***\n",
        "\n",
        "Lemmatize the `gettysburg` address.\n",
        "\n",
        "However, this time, we will also take a look at the speech, before and after lemmatization, and try to adjust the kind of changes that take place to make the piece more machine friendly.\n",
        "\n",
        "\n",
        "- Print the `gettysburg` address to the console.\n",
        "- Loop over doc and extract the lemma for each token of `gettysburg`.\n",
        "- Convert `lemmas` into a string using `join`."
      ],
      "metadata": {
        "id": "HOYgVWJL5YGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the en_core_web_sm model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a Doc object\n",
        "doc = nlp(gettysburg)\n",
        "\n",
        "# Generate lemmas\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "\n",
        "# Convert lemmas into a string\n",
        "print(' '.join(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGM1toR96SLM",
        "outputId": "c37fc772-a25a-4004-8648-88e241b7a148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "four score and seven year ago our father bring forth on this continent , a new nation , conceive in Liberty , and dedicate to the proposition that all man be create equal . now we be engage in a great civil war , test whether that nation , or any nation so conceive and so dedicated , can long endure . we be meet on a great battlefield of that war . we 've come to dedicate a portion of that field , as a final resting place for those who here give their life that that nation might live . it be altogether fitting and proper that we should do this . but , in a large sense , we can not dedicate - we can not consecrate - we can not hallow - this ground . the brave man , living and dead , who struggle here , have consecrate it , far above our poor power to add or detract . the world will little note , nor long remember what we say here , but it can never forget what they do here . it be for we the living , rather , to be dedicate here to the unfinished work which they who fight here have thus far so nobly advanced . it be rather for we to be here dedicate to the great task remain before we - that from these honored dead we take increased devotion to that cause for which they give the last full measure of devotion - that we here highly resolve that these dead shall not have die in vain - that this nation , under God , shall have a new birth of freedom - and that government of the people , by the people , for the people , shall not perish from the earth .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Cleaning a blog post***\n",
        "\n",
        "In this exercise, you have been given an excerpt from a blog post. Your task is to clean this text into a more machine friendly format. This will involve converting to lowercase, lemmatization and removing stopwords, punctuations and non-alphabetic characters.\n",
        "\n",
        "The excerpt is available as a string `blog` and has been printed to the console. The list of stopwords are available as `stopwords`.\n",
        "\n",
        "\n",
        "- Using list comprehension, loop through `doc` to extract the `lemma_` of each token.\n",
        "- Remove stopwords and non-alphabetic tokens using `stopwords` and **`isalpha()`**."
      ],
      "metadata": {
        "id": "cChWUIKp8VOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blog = '\\nTwenty-first-century politics has witnessed an alarming rise of populism in the U.S. and Europe. The first warning signs came with the UK Brexit Referendum vote in 2016 swinging in the way of Leave. This was followed by a stupendous victory by billionaire Donald Trump to become the 45th President of the United States in November 2016. Since then, Europe has seen a steady rise in populist and far-right parties that have capitalized on Europe’s Immigration Crisis to raise nationalist and anti-Europe sentiments. Some instances include Alternative for Germany (AfD) winning 12.6% of all seats and entering the Bundestag, thus upsetting Germany’s political order for the first time since the Second World War, the success of the Five Star Movement in Italy and the surge in popularity of neo-nazism and neo-fascism in countries such as Hungary, Czech Republic, Poland and Austria.\\n'\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load model and create Doc object\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(blog)\n",
        "\n",
        "# Generate lemmatized tokens\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "\n",
        "# Remove stopwords and non-alphabetic tokens\n",
        "a_lemmas = [lemma for lemma in lemmas \n",
        "            if lemma.isalpha() and lemma not in stopwords]\n",
        "\n",
        "# Print string after text cleaning\n",
        "print(' '.join(a_lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCqSAQ-q6TAE",
        "outputId": "9c5cf342-065a-4046-da22-db5c58a68389"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "century politic witness alarming rise populism Europe warning sign come UK Brexit Referendum vote swinge way Leave follow stupendous victory billionaire Donald Trump President United States November Europe steady rise populist far right party capitalize Europe Immigration Crisis raise nationalist anti europe sentiment instance include alternative Germany AfD win seat enter Bundestag upset Germany political order time Second World War success Five Star Movement Italy surge popularity neo nazism neo fascism country Hungary Czech Republic Poland Austria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Take a look at the cleaned text; it is lowercased and devoid of numbers, punctuations and commonly used stopwords. Also, note that the word U.S. was present in the original text. Since it had periods in between, our text cleaning process completely removed it. This may not be ideal behavior. It is always advisable to use your custom functions in place of **`isalpha()`** for more nuanced cases.\n",
        "\n",
        " ## ***Cleaning TED talks in a dataframe***\n",
        "\n",
        "In this exercise, we will revisit the TED Talks from the first chapter. You have been a given a dataframe `ted` consisting of 5 TED Talks. Your task is to clean these talks using techniques discussed earlier by writing a function preprocess and applying it to the transcript feature of the dataframe.\n",
        "\n",
        "The stopwords list is available as `stopwords`.\n",
        "\n",
        "\n",
        "- Generate the `Doc` object for text. Ignore the `disable` argument for now.\n",
        "- Generate lemmas using list comprehension using the **`lemma_`** attribute.\n",
        "- Remove non-alphabetic characters using **`isalpha()`** in the `if` condition."
      ],
      "metadata": {
        "id": "MJaOfLeq9noH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ted = pd.read_csv('ted.csv').head(20)\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess(text):\n",
        "  \t# Create Doc object\n",
        "    doc = nlp(text, disable=['ner', 'parser'])\n",
        "    # Generate lemmas\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    # Remove stopwords and non-alphabetic characters\n",
        "    a_lemmas = [lemma for lemma in lemmas \n",
        "            if lemma.isalpha() and lemma not in stopwords]\n",
        "    \n",
        "    return ' '.join(a_lemmas)\n",
        "  \n",
        "# Apply preprocess to ted['transcript']\n",
        "ted['transcript'] = ted['transcript'].apply(preprocess)\n",
        "print(ted['transcript'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNtL8G2Q9FQE",
        "outputId": "a7db956b-5c77-4ced-ffee-2bcfa5b5406a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     talk new lecture TED I illusion create TED I t...\n",
            "1     representation brain brain break left half log...\n",
            "2     great honor today share Digital Universe creat...\n",
            "3     passion music technology thing combination thi...\n",
            "4     use want computer new program programming requ...\n",
            "5     I neuroscientist mixed background physics medi...\n",
            "6     Pat Mitchell day January begin like work love ...\n",
            "7     Taylor Wilson I year old I nuclear physicist l...\n",
            "8     I grow Northern Ireland right north end absolu...\n",
            "9     I publish article New York Times Modern Love c...\n",
            "10    Joseph Member Parliament Kenya picture Maasai ...\n",
            "11    hi I talk little bit music machine life specif...\n",
            "12    hi let I ask audience question lie child raise...\n",
            "13    historical record allow know ancient Greeks dr...\n",
            "14    good morning I little boy I experience change ...\n",
            "15    I slide I year ago time I short slide morning ...\n",
            "16    I like world I like share year old love story ...\n",
            "17    I fail woman I fail feminist I passionate opin...\n",
            "18    revolution century significant longevity revol...\n",
            "19    today baffled lady observe shell soul dwellsan...\n",
            "Name: transcript, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have preprocessed all the TED talk transcripts contained in ted and it is now in a good shape to perform operations such as vectorization.\n",
        "\n",
        "## ***POS tagging in Lord of the Flies***\n",
        "\n",
        "Perform part-of-speech tagging on a famous passage from one of the most well-known novels of all time, Lord of the Flies, authored by William Golding.\n",
        "\n",
        "The passage is available as `lotf` and has already been printed to the console.\n",
        "\n",
        "- Load the `en_core_web_sm` model.\n",
        "- Create a `doc` object for lotf using **`nlp()`**.\n",
        "- Using the **`text`** and **`pos_`** attributes, generate tokens and their corresponding POS tags."
      ],
      "metadata": {
        "id": "S1v3FHtO-8lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lotf = 'He found himself understanding the wearisomeness of this life, where every path was an improvisation and a considerable part of one’s waking life was spent watching one’s feet.'\n",
        "\n",
        "# Load the en_core_web_sm model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a Doc object\n",
        "doc = nlp(lotf)\n",
        "\n",
        "# Generate tokens and pos tags\n",
        "pos = [(token.text, token.pos_) for token in doc]\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2vuU-1C-wgg",
        "outputId": "ed38e675-38a9-4742-cb37-4f9cfb6d1301"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRON'), ('found', 'VERB'), ('himself', 'PRON'), ('understanding', 'VERB'), ('the', 'DET'), ('wearisomeness', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('life', 'NOUN'), (',', 'PUNCT'), ('where', 'SCONJ'), ('every', 'DET'), ('path', 'NOUN'), ('was', 'AUX'), ('an', 'DET'), ('improvisation', 'NOUN'), ('and', 'CCONJ'), ('a', 'DET'), ('considerable', 'ADJ'), ('part', 'NOUN'), ('of', 'ADP'), ('one', 'NUM'), ('’s', 'NUM'), ('waking', 'VERB'), ('life', 'NOUN'), ('was', 'AUX'), ('spent', 'VERB'), ('watching', 'VERB'), ('one', 'NUM'), ('’s', 'NUM'), ('feet', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the various POS tags attached to each token and evaluate if they make intuitive sense to you. You will notice that they are indeed labelled correctly according to the standard rules of English grammar.\n",
        "\n",
        "## ***Counting nouns in a piece of text***\n",
        "\n",
        "In this exercise, we will write two functions, `nouns()` and `proper_nouns()` that will count the number of other nouns and proper nouns in a piece of text respectively.\n",
        "\n",
        "These functions will take in a piece of text and generate a list containing the POS tags for each word. It will then return the number of proper nouns/other nouns that the text contains. We will use these functions in the next exercise to generate interesting insights about fake news.\n",
        "\n",
        "The `en_core_web_sm` model has already been loaded as `nlp` in this exercise.\n",
        "\n",
        "- Using the list **`count`** method, count the number of proper nouns (annotated as `PROPN`) in the `pos` list.\n",
        "\n",
        "\n",
        "- Using the list **`count`** method, count the number of other nouns (annotated as `NOUN`) in the `pos` list."
      ],
      "metadata": {
        "id": "62bWywBhDQR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Returns number of proper nouns\n",
        "def proper_nouns(text, model=nlp):\n",
        "  \t# Create doc object\n",
        "    doc = model(text)\n",
        "    # Generate list of POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    \n",
        "    # Return number of proper nouns\n",
        "    return pos.count('PROPN')\n",
        "\n",
        "print(proper_nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6QOMPWy_AXy",
        "outputId": "b1b3db1a-a713-445c-a0aa-f7d1fd36765e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Returns number of other nouns\n",
        "def nouns(text, model=nlp):\n",
        "  \t# Create doc object\n",
        "    doc = model(text)\n",
        "    # Generate list of POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    \n",
        "    # Return number of other nouns\n",
        "    return pos.count('NOUN')\n",
        "\n",
        "print(nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I-cJiYuEbbi",
        "outputId": "e9cc8ee1-2bdf-4c4d-8ca4-271f8092d860"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Noun usage in fake news***\n",
        "\n",
        "In this exercise, you have been given a dataframe `headlines` that contains news headlines that are either fake or real. Your task is to generate two new features `num_propn` and `num_noun` that represent the number of proper nouns and other nouns contained in the `title` feature of `headlines`.\n",
        "\n",
        "Next, we will compute the mean number of proper nouns and other nouns used in fake and real news headlines and compare the values. If there is a remarkable difference, then there is a good chance that using the `num_propn` and `num_noun` features in fake news detectors will improve its performance.\n",
        "\n",
        "To accomplish this task, the functions `proper_nouns` and `nouns` that you had built above have already been made available to you.\n",
        "\n",
        "- Create a new feature `num_propn` by applying `proper_nouns` to headlines `['title']`.\n",
        "\n",
        "- Filter headlines to compute the mean number of proper nouns in fake news using the **`mean`** method.\n",
        "\n",
        "- Repeat the process for other nouns: create a feature `'num_noun'` using `nouns` and compute the mean of other nouns"
      ],
      "metadata": {
        "id": "4CZjfYJIErJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headlines = pd.read_csv('fakenews.csv').drop(columns='Unnamed: 0')\n",
        "\n",
        "headlines['num_propn'] = headlines['title'].apply(proper_nouns)\n",
        "\n",
        "# Compute mean of proper nouns\n",
        "real_propn = headlines[headlines['label'] == 'REAL']['num_propn'].mean()\n",
        "fake_propn = headlines[headlines['label'] == 'FAKE']['num_propn'].mean()\n",
        "\n",
        "# Print results\n",
        "print(\"Mean no. of proper nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_propn, fake_propn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvHFRMv1Ejer",
        "outputId": "456c973e-6a34-43d0-ce49-0aeb9a47c775"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean no. of proper nouns in real and fake headlines are 2.37 and 4.81 respectively\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headlines['num_noun'] = headlines['title'].apply(nouns)\n",
        "\n",
        "# Compute mean of other nouns\n",
        "real_noun = headlines[headlines['label'] == 'REAL']['num_noun'].mean()\n",
        "fake_noun = headlines[headlines['label'] == 'FAKE']['num_noun'].mean()\n",
        "\n",
        "# Print results\n",
        "print(\"Mean no. of other nouns in real and fake headlines are %.2f and %.2f respectively\"%(real_noun, fake_noun))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5leOyKGeIJW6",
        "outputId": "2f997ffb-bcb3-47e8-f2e6-ea16da80325e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean no. of other nouns in real and fake headlines are 2.39 and 1.60 respectively\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the mean number of proper nouns is considerably higher for fake news than it is for real news. The opposite seems to be true in the case of other nouns. This fact can be put to great use in designing fake news detectors.\n",
        "\n",
        "## ***Named entities in a sentence***\n",
        "\n",
        "In this exercise, we will identify and classify the labels of various named entities in a body of text using one of spaCy's statistical models. We will also verify the veracity of these labels.\n",
        "\n",
        "- Use **`spacy.load()`** to load the ` en_core_web_sm` model.\n",
        "- Create a Doc instance `doc` using `text` and `nlp`.\n",
        "- Loop over `doc.ents` to print all the named entities and their corresponding labels."
      ],
      "metadata": {
        "id": "7plgePlNIq4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the required model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a Doc instance \n",
        "text = 'Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.'\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print all named entities and their labels\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfOx7WGKIhfF",
        "outputId": "b6117cc3-6c6e-4cf8-d333-729176cbd487"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sundar Pichai PERSON\n",
            "Google ORG\n",
            "Mountain View GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Notice how the model correctly predicted the labels of Google and Mountain View but mislabeled Sundar Pichai as an organization (แต่ในเวอร์ชั่น 3 ด้านบน ทำได้ตรงถูกต้องแล้ว). As discussed in the video, the predictions of the model depend strongly on the data it is trained on. It is possible to train spaCy models on your custom data.\n",
        "\n",
        "## ***Identifying people mentioned in a news article***\n",
        "\n",
        "In this exercise, you have been given an excerpt from a news article published in TechCrunch. Your task is to write a function `find_people` that identifies the names of people that have been mentioned in a particular piece of text. You will then use `find_people` to identify the people of interest in the article.\n",
        "\n",
        "The article is available as the string `tc` and has been printed to theconsole. The required `spacy` model has also been already loaded as `nlp`.\n",
        "\n",
        "- Create a Doc object for `text`.\n",
        "- Using list comprehension, loop through `doc.ents` and create a list of named entities whose label is `PERSON`.\n",
        "- Using `find_persons()`, print the people mentioned in `tc`."
      ],
      "metadata": {
        "id": "dhYZApgwK8Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tc = \"\\nIt’s' been a busy day for Facebook  exec op-eds. Earlier this morning, Sheryl Sandberg broke the site’s silence around the Christchurch massacre, and now Mark Zuckerberg is calling on governments and other bodies to increase regulation around the sorts of data Facebook traffics in. He’s hoping to get out in front of heavy-handed regulation and get a seat at the table shaping it.\\n\"\n",
        "\n",
        "def find_persons(text):\n",
        "  # Create Doc object\n",
        "  doc = nlp(text)\n",
        "  \n",
        "  # Identify the persons\n",
        "  persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
        "  \n",
        "  # Return persons\n",
        "  return persons\n",
        "\n",
        "print(find_persons(tc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qj-Mh8jKwbi",
        "outputId": "d3ca530c-8cc4-47d9-b79a-a04bf61d8827"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Facebook', 'Sheryl Sandberg', 'Mark Zuckerberg', 'Facebook']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(tc)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V157YxQUL0im",
        "outputId": "4ce0cf0e-974f-4c3b-93f6-816be56540a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Facebook PERSON\n",
            "Earlier this morning TIME\n",
            "Sheryl Sandberg PERSON\n",
            "Christchurch ORG\n",
            "Mark Zuckerberg PERSON\n",
            "Facebook PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The article was related to Facebook and our function correctly identified both the people mentioned, but incorrectly identified Facebook. You can now see how NER could be used in a variety of applications. Publishers may use a technique like this to classify news articles by the people mentioned in them. A question answering system could also use something like this to answer questions such as 'Who are the people mentioned in this passage?'. \n",
        "\n",
        "# **Bag of words**\n",
        "- Extract word tokens\n",
        "- Compute frequency of word tokens\n",
        "- Construct a word vector out of these frequencies and vocabulary of corpus\n",
        "\n",
        "### **Corpus**\n",
        "\n",
        "```\n",
        "\"The lion is the king of the jungle\"\n",
        "```\n",
        "```\n",
        "\"Lions have lifespans of a decade\"\n",
        "```\n",
        "```\n",
        "\"The lion is an endangered species\"\n",
        "```\n",
        "\n",
        "### **Vocabulary →** `a` , `an` , `decade` , `endangered` , `have` , `is` , `jungle` , `king` , `lifespans` , `lion` ,`Lions` , `of` , `species` , `the` , `The`\n",
        "\n",
        "- Word vectors have 15 dimensions.\n",
        "- Each value in the vector corresponds to the frequency of the corresponding word in the vocabulary.\n",
        "\n",
        "```\n",
        "\"The lion is the king of the jungle\"\n",
        "[0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1]\n",
        "```\n",
        "```\n",
        "\"Lions have lifespans of a decade\"\n",
        "[1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
        "```\n",
        "```\n",
        "\"The lion is an endangered species\"\n",
        "[0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
        "```"
      ],
      "metadata": {
        "id": "ls3d0MBcMSK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bag of words model using sklearn**"
      ],
      "metadata": {
        "id": "P18O3_YVK5C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = pd.Series(['The lion is the king of the jungle',\n",
        "                    'Lions have lifespans of a decade',\n",
        "                    'The lion is an endangered species'])\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "print(bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l29AukFhMEOd",
        "outputId": "3fa8f94c-aaa6-4f62-c2d7-6be2a706d696"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 1 1 1 0 1 0 1 0 3]\n",
            " [0 1 0 1 0 0 0 1 0 1 1 0 0]\n",
            " [1 0 1 0 1 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตัวเลขไม่เหมือนกัน เพราะ CountVectorizer ทำเป็น lowercase ก่อน\n",
        "\n",
        "## ***BoW model for movie taglines***\n",
        "\n",
        "In this exercise, you have been provided with a corpus of more than 7000 movie tag lines. Your job is to generate the bag of words representation `bow_matrix` for these taglines. For this exercise, we will ignore the text preprocessing step and generate `bow_matrix` directly.\n",
        "\n",
        "We will also investigate the shape of the resultant `bow_matrix`. \n",
        "\n",
        "- Import the **`CountVectorizer`** class from **`sklearn`**.\n",
        "- Instantiate a **`CountVectorizer`** object. Name it `vectorizer`.\n",
        "- Using `fit_transform()`, generate `bow_matrix` for corpus."
      ],
      "metadata": {
        "id": "g3IzKDM4MA7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.read_csv('movie_overviews.csv').dropna()['tagline']\n",
        "print(corpus.shape, \"\\n\")\n",
        "\n",
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Print the shape of bow_matrix\n",
        "print(bow_matrix.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx_CtoRiLIgW",
        "outputId": "95d161ce-e239-4b6a-b58e-b5a385db0382"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7033,) \n",
            "\n",
            "(7033, 6614)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You now know how to generate a bag of words representation for a given corpus of documents. Notice that the word vectors created have more than 6600 dimensions. However, most of these dimensions have a value of zero since most words do not occur in a particular tagline.\n",
        "\n",
        " ## ***Analyzing dimensionality and preprocessing***\n",
        "\n",
        "In this exercise, you have been provided with a `lem_corpus` which contains the pre-processed versions of the movie taglines from the previous exercise. In other words, the taglines have been lowercased and lemmatized, and stopwords have been removed.\n",
        "\n",
        "Your job is to generate the bag of words representation `bow_lem_matrix` for these lemmatized taglines and compare its shape with that of `bow_matrix` obtained in the previous exercise. \n",
        "\n",
        "\n",
        "- Import the **`CountVectorizer`** class from `sklearn`.\n",
        "- Instantiate a **`CountVectorizer`** object. Name it `vectorizer`.\n",
        "- Using **`fit_transform()`**, generate `bow_lem_matrix` for `lem_corpus`."
      ],
      "metadata": {
        "id": "aQ_lCge0Q6Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess(text):\n",
        "  \t# Create Doc object\n",
        "    doc = nlp(text, disable=['ner', 'parser'])\n",
        "    # Generate lemmas\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    # Remove stopwords and non-alphabetic characters\n",
        "    a_lemmas = [lemma.lower() for lemma in lemmas \n",
        "            if lemma.isalpha() and lemma not in stopwords]\n",
        "    \n",
        "    return ' '.join(a_lemmas)\n",
        "\n",
        "lem_corpus = corpus.apply(preprocess)\n",
        "print(lem_corpus.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbWT4fJNQMuV",
        "outputId": "d6004578-e293-4cde-f48b-cef86e81c7f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    roll dice unleash excitement\n",
            "2           yell fight ready love\n",
            "3    friend people let let forget\n",
            "4      world normal surprise life\n",
            "5          los angeles crime saga\n",
            "Name: tagline, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_lem_matrix = vectorizer.fit_transform(lem_corpus)\n",
        "\n",
        "# Print the shape of bow_lem_matrix\n",
        "print(bow_lem_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noiBCwajSDOy",
        "outputId": "256d7039-664c-4ca8-ad6b-0a29989727cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7033, 5283)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the number of features have reduced significantly from around 6,614 to around 5,283 for pre-processed movie taglines. The reduced number of dimensions on account of text preprocessing usually leads to better performance when conducting machine learning and it is a good idea to consider it. However, as mentioned in a previous lesson, the final decision always depends on the nature of the application.\n",
        "\n",
        "## ***Mapping feature indices with feature names***\n",
        "\n",
        "**`CountVectorizer`** doesn't necessarily index the vocabulary in alphabetical order. In this exercise, we will learn to map each feature index to its corresponding feature name from the vocabulary.\n",
        "\n",
        "We will use the same three sentences on lions from the above. The sentences are available in a list named `corpus`.\n",
        "\n",
        "\n",
        "- Instantiate a **`CountVectorizer`** object. Name it `vectorizer`.\n",
        "- Using **`fit_transform()`**, generate `bow_matrix` for `corpus`.\n",
        "- Using the **`get_feature_names_out()`** method, map the column names to the corresponding word in the vocabulary."
      ],
      "metadata": {
        "id": "yZzwq1ibTdlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['The lion is the king of the jungle', 'Lions have lifespans of a decade', 'The lion is an endangered species']\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert bow_matrix into a DataFrame\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
        "\n",
        "# Map the column names to vocabulary \n",
        "bow_df.columns = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print bow_df\n",
        "bow_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wpocpxDrTalh",
        "outputId": "63b55222-221d-4e8e-8b06-c63ef38fad06"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   an  decade  endangered  have  is  jungle  king  lifespans  lion  lions  of  \\\n",
              "0   0       0           0     0   1       1     1          0     1      0   1   \n",
              "1   0       1           0     1   0       0     0          1     0      1   1   \n",
              "2   1       0           1     0   1       0     0          0     1      0   0   \n",
              "\n",
              "   species  the  \n",
              "0        0    3  \n",
              "1        0    0  \n",
              "2        1    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16008198-c5b3-48e4-a020-4885d11a1d03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>decade</th>\n",
              "      <th>endangered</th>\n",
              "      <th>have</th>\n",
              "      <th>is</th>\n",
              "      <th>jungle</th>\n",
              "      <th>king</th>\n",
              "      <th>lifespans</th>\n",
              "      <th>lion</th>\n",
              "      <th>lions</th>\n",
              "      <th>of</th>\n",
              "      <th>species</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16008198-c5b3-48e4-a020-4885d11a1d03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16008198-c5b3-48e4-a020-4885d11a1d03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16008198-c5b3-48e4-a020-4885d11a1d03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that the column names refer to the token whose frequency is being recorded. Therefore, since the first column name is an, ***the first feature \n",
        "represents the number of times the word 'an' occurs*** in a particular sentence. **`get_feature_names_out()`** essentially gives us a list which represents the mapping of the feature indices to the feature name in the vocabulary.\n",
        "\n",
        "# **CountVectorizer arguments**\n",
        "\n",
        "- `lowercase` : `False` , `True`\n",
        "- `strip_accents` : `'unciode'` , `'ascii'` , `None`\n",
        "- `stop_words` : `'english'` , `list` , `None`\n",
        "- `token_pattern` : `regex`\n",
        "- `tokenizer` : `function`\n",
        "\n",
        "## ***BoW vectors for movie reviews***\n",
        "\n",
        "In this exercise, you have been given two pandas Series, `X_train` and `X_test`, which consist of movie reviews. They represent the training and the test review data respectively. Your task is to preprocess the reviews and generate BoW vectors for these two sets using **`CountVectorizer`**.\n",
        "\n",
        "Once we have generated the BoW vector matrices `X_train_bow` and `X_test_bow`, we will be in a very good position to apply a machine learning model to it and conduct sentiment analysis.\n",
        "\n",
        "- Import **`CountVectorizer`** from the `sklearn` library.\n",
        "- Instantiate a **`CountVectorizer`** object named `vectorizer`. Ensure that all words are converted to lowercase and english stopwords are removed.\n",
        "- Using `X_train`, fit vectorizer and then use it to transform `X_train` to generate the set of BoW vectors `X_train_bow`.\n",
        "- Transform `X_test` using vectorizer to generate the set of BoW vectors `X_test_bow`."
      ],
      "metadata": {
        "id": "0xyZFzqbVDge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_reviews_clean.csv')\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.25)\n",
        "\n",
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
        "\n",
        "# Fit and transform X_train\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform X_test\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Print shape of X_train_bow and X_test_bow\n",
        "print(X_train_bow.shape)\n",
        "print(X_test_bow.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa_7sT8iU0Ab",
        "outputId": "67560cda-0c95-4591-c698-3f0dabca2ed0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(750, 15008)\n",
            "(250, 15008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both `X_train_bow` and `X_test_bow` have 15,009 features. There were words present in `X_test` that were not in `X_train`. CountVectorizer chose to ignore them in order to ensure that the dimensions of both sets remain the same.\n",
        "\n",
        "## ***Predicting the sentiment of a movie review***\n",
        "\n",
        "In the previous exercise, you generated the bag-of-words representations for the training and test movie review data. In this exercise, we will use this model to train a Naive Bayes classifier that can detect the sentiment of a movie review and compute its accuracy. Note that since this is a binary classification problem, the model is only capable of classifying a review as either positive (1) or negative (0). It is incapable of detecting neutral reviews.\n",
        "\n",
        "In case you don't recall, the training and test BoW vectors are available as `X_train_bow` and `X_test_bow` respectively. The corresponding labels are available as `y_train` and `y_test` respectively. Also, for your reference, the original movie review dataset is available as `df`.\n",
        "\n",
        "- Instantiate an object of **`MultinomialNB`**. Name it `clf`.\n",
        "- Fit `clf` using `X_train_bow` and `y_train`.\n",
        "- Measure the accuracy of `clf` using `X_test_bow` and `y_test`."
      ],
      "metadata": {
        "id": "1QfcsCU-Zuxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MultinomialNB object\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Fit the classifier\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "# Measure the accuracy\n",
        "accuracy = clf.score(X_test_bow, y_test)\n",
        "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
        "\n",
        "# Predict the sentiment of a negative review\n",
        "review = \"The movie was terrible. The music was underwhelming and the acting mediocre.\"\n",
        "prediction = clf.predict(vectorizer.transform([review]))[0]\n",
        "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4611fiRZHrC",
        "outputId": "5cc2a566-49af-4bc9-db4a-86206329892e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the classifier on the test set is 0.828\n",
            "The sentiment predicted by the classifier is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the accuracy of the classifier is 84.4%. Considering the fact that it was trained on only 750 reviews, this is reasonably good performance. The classifier also correctly predicts the sentiment of a mini negative review which we passed into it.\n",
        "\n",
        "# **BoW shortcomings**\n",
        "\n",
        "```\n",
        "review                                 label\n",
        "'The movie was good and not boring' positive\n",
        "'The movie was not good and boring' negative\n",
        "```\n",
        "- Exactly the same BoW representation!\n",
        "- Context of the words is lost.\n",
        "- Sentiment dependent on the position of 'not'.\n",
        "\n",
        "# **n-grams**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "'for you a thousand times over'\n",
        "```\n",
        "- n = 2, n-grams:\n",
        "```\n",
        "[\n",
        "'for you',\n",
        "'you a',\n",
        "'a thousand',\n",
        "'thousand times',\n",
        "'times over'\n",
        "]\n",
        "```\n",
        "\n",
        "# **Building n-gram models using scikit-learn**\n",
        "\n",
        "Generates only bigrams.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Mbeb6u2a8gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = CountVectorizer(ngram_range=(2,2))"
      ],
      "metadata": {
        "id": "OkEu3U4mauKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates unigrams, bigrams and trigrams."
      ],
      "metadata": {
        "id": "0bKyaCtinLYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams = CountVectorizer(ngram_range=(1,3))"
      ],
      "metadata": {
        "id": "edfex7YanN_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***n-gram models for movie tag lines***\n",
        "\n",
        "A `corpus` has more than 9000 movie tag lines. Our job is to generate n-gram models up to n equal to 1, n equal to 2 and n equal to 3 for this data and discover the number of features for each model.\n",
        "\n",
        "We will then compare the number of features generated for each model.\n",
        "\n",
        "- Generate an n-gram model with n-grams up to n=1. Name it `ng1`\n",
        "- Generate an n-gram model with n-grams up to n=2. Name it `ng2`\n",
        "- Generate an n-Gram Model with n-grams up to n=3. Name it `ng3`\n",
        "- Print the number of features for each model."
      ],
      "metadata": {
        "id": "DS4VlxIgnoq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.read_csv('movie_overviews.csv').dropna()['tagline']\n",
        "\n",
        "# Generate n-grams upto n=1\n",
        "vectorizer_ng1 = CountVectorizer(ngram_range=(1,1))\n",
        "ng1 = vectorizer_ng1.fit_transform(corpus)\n",
        "\n",
        "# Generate n-grams upto n=2\n",
        "vectorizer_ng2 = CountVectorizer(ngram_range=(1,2))\n",
        "ng2 = vectorizer_ng2.fit_transform(corpus)\n",
        "\n",
        "# Generate n-grams upto n=3\n",
        "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
        "ng3 = vectorizer_ng3.fit_transform(corpus)\n",
        "\n",
        "# Print the number of features for each model\n",
        "print(\"ng1, ng2 and ng3 have %i, %i and %i features respectively\" % (ng1.shape[1], ng2.shape[1], ng3.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJB-daNAn_hk",
        "outputId": "b7cd0f85-ce7b-444a-dce4-9667b67eaa2a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ng1, ng2 and ng3 have 6614, 37100 and 76881 features respectively\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now know how to generate n-gram models containing higher order n-grams. Notice that ng2 has over 37,000 features whereas ng3 has over 76,000 features. This is much greater than the 6,000 dimensions obtained for ng1. As the n-gram range increases, so does the number of features, leading to increased computational costs and a problem known as the curse of dimensionality.\n",
        "\n",
        "## ***Higher order n-grams for sentiment analysis***\n",
        "\n",
        "Similar to a previous exercise, we are going to build a classifier that can detect if the review of a particular movie is positive or negative. However, this time, we will use n-grams up to n=2 for the task.\n",
        "\n",
        "The n-gram training reviews are available as `X_train_ng`. The corresponding test reviews are available as `X_test_ng`. Finally, use `y_train` and `y_test` to access the training and test sentiment classes respectively.\n",
        "\n",
        "- Define an instance of **`MultinomialNB`**. Name it `clf_ng`\n",
        "- Fit the classifier on `X_train_ng` and `y_train`.\n",
        "- Measure accuracy on `X_test_ng` and `y_test` the using **`score()`** method."
      ],
      "metadata": {
        "id": "t0z09E44oqyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_reviews_clean.csv')\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.25)\n",
        "ng_vectorizer = CountVectorizer(lowercase=True, stop_words='english')#, ngram_range=(1, 2))\n",
        "X_train_ng = ng_vectorizer.fit_transform(X_train)\n",
        "X_test_ng = ng_vectorizer.transform(X_test)\n",
        "\n",
        "# Define an instance of MultinomialNB \n",
        "clf_ng = MultinomialNB()\n",
        "\n",
        "# Fit the classifier \n",
        "clf_ng.fit(X_train_ng, y_train)\n",
        "\n",
        "# Measure the accuracy \n",
        "accuracy = clf_ng.score(X_test_ng, y_test)\n",
        "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
        "\n",
        "# Predict the sentiment of a negative review\n",
        "review = \"The movie was terrible. The music was underwhelming and the acting mediocre.\"\n",
        "prediction = clf_ng.predict(ng_vectorizer.transform([review]))[0]\n",
        "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVQDnzLTolj6",
        "outputId": "4d606c5b-b5c9-4404-bdc5-3128a420e413"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the classifier on the test set is 0.832\n",
            "The sentiment predicted by the classifier is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Comparing performance of n-gram models***\n",
        "\n",
        "You now know how to conduct sentiment analysis by converting text into various n-gram representations and feeding them to a classifier. In this exercise, we will conduct sentiment analysis for the same movie reviews from before using two n-gram models: unigrams and n-grams upto n equal to 3.\n",
        "\n",
        "We will then compare the performance using three criteria: accuracy of the model on the test set, time taken to execute the program and the number of features created when generating the n-gram representation.\n",
        "\n",
        "- Initialize a **`CountVectorizer`** object such that it generates unigrams.\n",
        "- Initialize a **`CountVectorizer`** object such that it generates ngrams upto n=3."
      ],
      "metadata": {
        "id": "szrYTjLZr0gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# Splitting the data into training and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.5, random_state=42, stratify=df['sentiment'])\n",
        "\n",
        "# Generating ngrams\n",
        "vectorizer = CountVectorizer()\n",
        "train_X = vectorizer.fit_transform(train_X)\n",
        "test_X = vectorizer.transform(test_X)\n",
        "\n",
        "# Fit classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# Print accuracy, time and number of dimensions\n",
        "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. The ngram representation had %i features.\" % (time.time() - start_time, clf.score(test_X, test_y), train_X.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGHXpn4OqdhN",
        "outputId": "6878f92c-a20c-43ca-f383-86b2633e65f7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program took 1.325 seconds to complete. The accuracy on the test set is 0.75. The ngram representation had 12347 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "# Splitting the data into training and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(df['review'], df['sentiment'], test_size=0.5, random_state=42, stratify=df['sentiment'])\n",
        "\n",
        "# Generating ngrams\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "train_X = vectorizer.fit_transform(train_X)\n",
        "test_X = vectorizer.transform(test_X)\n",
        "\n",
        "# Fit classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# Print accuracy, time and number of dimensions\n",
        "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. The ngram representation had %i features.\" % (time.time() - start_time, clf.score(test_X, test_y), train_X.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-0N4njesRYv",
        "outputId": "4aa6bae0-5afd-498f-d1e6-f4e8722f2a67"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program took 2.500 seconds to complete. The accuracy on the test set is 0.77. The ngram representation had 178240 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite taking higher computation time and generating more features, the classifier only performs marginally better in the latter case, producing an accuracy of 77% in comparison to the 75% for the unigram model.\n",
        "\n",
        "## **tf-idf document vectors**\n",
        "\n",
        "### **Motivation**\n",
        "\n",
        "- Some words occur very commonly across all documents\n",
        "- Corpus of documents on the universe\n",
        "   - One document has `jupiter` and `universe` occurring 20 times each.\n",
        "   - `jupiter` rarely occurs in the other documents. `universe` is common.\n",
        "   -  Give more weight to `jupiter` on account of exclusivity.\n",
        "\n",
        "$$w_{ij} = tf_{ij} \\times \\log\\left(\\frac{N}{df_i} \\right)$$\n",
        "\n",
        "- $w_{ij}$ ⟶ weight of word $i$ in document $j$\n",
        "- $tf_{ij}$ ⟶ frequency of word $i$ in document $j$\n",
        "- $N$ ⟶ number of documents in the corpus\n",
        "- $df_i$  ⟶ number of documents containing word $i$\n",
        "\n",
        "## ***tf-idf vectors for TED talks***\n",
        "\n",
        "In this exercise, you have been given a corpus `ted` which contains the transcripts of 500 TED Talks. Your task is to generate the tf-idf vectors for these talks.\n",
        "\n",
        "In a later lesson, we will use these vectors to generate recommendations of similar talks based on the transcript.\n",
        "\n",
        "- Import **`TfidfVectorizer`** from **`sklearn`**.\n",
        "- Create a **`TfidfVectorizer`** object. Name it `vectorizer`.\n",
        "- Generate `tfidf_matrix` for `ted` using the **`fit_transform()`** method."
      ],
      "metadata": {
        "id": "BFxrHT35syYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ted = pd.read_csv('ted.csv')['transcript']\n",
        "\n",
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "tfidf_matrix = vectorizer.fit_transform(ted)\n",
        "\n",
        "# Print the shape of tfidf_matrix\n",
        "print(tfidf_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm3Rt9_0sicQ",
        "outputId": "020bd85f-1c64-4c19-c382-92e0dd655275"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 29158)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now know how to generate tf-idf vectors for a given corpus of text. You can use these vectors to perform predictive modeling just like we did with **`CountVectorizer`**. In the next few lessons, we will see another extremely useful application of the vectorized form of documents: generating recommendations.\n",
        "\n",
        "# **Cosine Similarity**\n",
        "\n",
        "- เอามาใช้ดูว่า word vectors มันคล้ายกันไหม\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "- มีค่าระหว่าง 0 ถึง 1\n",
        "- ถ้าได้ 1 แปลว่า เหมือนกันเป๊ะ ได้ 0 แปลว่าไม่เหมือนกันเลย\n",
        "\n",
        "## ***Cosine similarity matrix of a corpus***\n",
        "\n",
        "You have been given a `corpus`, which is a list containing five sentences. Compute the cosine similarity matrix which contains the pairwise cosine similarity score for every pair of sentences (vectorized using tf-idf).\n",
        "\n",
        "Remember, the value corresponding to the ith row and jth column of a similarity matrix denotes the similarity score for the ith and jth vector.\n",
        "\n",
        "- Initialize an instance of **`TfidfVectorizer`**. Name it `tfidf_vectorizer`.\n",
        "- Using **`.fit_transform()`**, generate the tf-idf vectors for `corpus`. Name it `tfidf_matrix`.\n",
        "- Use `cosine_similarity()` and pass `tfidf_matrix` to compute the cosine similarity matrix `cosine_sim`."
      ],
      "metadata": {
        "id": "X3tgeAG47TvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus =  ['The sun is the largest celestial body in the solar system', 'The solar system consists of the sun and eight revolving planets', 'Ra was the Egyptian Sun God', 'The Pyramids were the pinnacle of Egyptian architecture', 'The quick brown fox jumps over the lazy dog']\n",
        "\n",
        "\n",
        "# Initialize an instance of tf-idf Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Generate the tf-idf vectors for the corpus\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Compute and print the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "print(cosine_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyQt16L56p0Q",
        "outputId": "fa3f5595-1dde-4883-d5b1-6a1210b5a11a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.36413198 0.18314713 0.18435251 0.16336438]\n",
            " [0.36413198 1.         0.15054075 0.21704584 0.11203887]\n",
            " [0.18314713 0.15054075 1.         0.21318602 0.07763512]\n",
            " [0.18435251 0.21704584 0.21318602 1.         0.12960089]\n",
            " [0.16336438 0.11203887 0.07763512 0.12960089 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the cosine similarity matrix lies at the heart of many practical systems such as ***recommenders***. From our similarity matrix, we see that the first and the second sentence are the most similar. Also the fifth sentence has, on average, the lowest pairwise cosine scores. This is intuitive as it contains entities that are not present in the other sentences.\n",
        "\n"
      ],
      "metadata": {
        "id": "8LebKXfBAS_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPNTmuXTANVQ",
        "outputId": "1e892e67-0f5d-4d2d-fdaa-cb99eb975027"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.33721756, 0.        , 0.33721756,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.33721756, 0.33721756, 0.        , 0.33721756,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.272065  ,\n",
              "        0.22583853, 0.272065  , 0.48205792, 0.        , 0.        ],\n",
              "       [0.34690677, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.34690677, 0.        , 0.        , 0.34690677, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2798822 , 0.        , 0.        , 0.34690677,\n",
              "        0.        , 0.        , 0.        , 0.34690677, 0.2798822 ,\n",
              "        0.23232751, 0.2798822 , 0.33060587, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.38787768, 0.        , 0.        ,\n",
              "        0.48076439, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.48076439, 0.        , 0.        ,\n",
              "        0.32197351, 0.        , 0.22908681, 0.48076439, 0.        ],\n",
              "       [0.        , 0.40128419, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.32375356, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.32375356, 0.        , 0.40128419, 0.        ,\n",
              "        0.40128419, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.38242813, 0.        , 0.40128419],\n",
              "       [0.        , 0.        , 0.        , 0.35559887, 0.        ,\n",
              "        0.        , 0.35559887, 0.        , 0.        , 0.35559887,\n",
              "        0.        , 0.        , 0.        , 0.35559887, 0.        ,\n",
              "        0.35559887, 0.        , 0.35559887, 0.        , 0.        ,\n",
              "        0.        , 0.35559887, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33888953, 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Comparing linear_kernel and cosine_similarity***\n",
        "\n",
        "A `tfidf_matrix` contains the tf-idf vectors of a thousand documents. Generate the cosine similarity matrix for these vectors first using **`cosine_similarity`** and then, using **`linear_kernel`**.\n",
        "\n",
        "We will then compare the computation times for both functions.\n",
        "\n",
        "- Compute the cosine similarity matrix for `tfidf_matrix` using **`cosine_similarity`**.\n",
        "\n",
        "- Compute the cosine similarity matrix for `tfidf_matrix` using **`linear_kernel`**."
      ],
      "metadata": {
        "id": "uc5ypc5OKp0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Record start time\n",
        "start = time.time()\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Print cosine similarity matrix\n",
        "print(cosine_sim)\n",
        "\n",
        "# Print time taken\n",
        "print(\"Time taken: %s seconds\" %(time.time() - start))\n",
        "\n",
        "# Record start time\n",
        "start = time.time()\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Print cosine similarity matrix\n",
        "print(cosine_sim)\n",
        "\n",
        "# Print time taken\n",
        "print(\"Time taken: %s seconds\" %(time.time() - start))"
      ],
      "metadata": {
        "id": "zyL81tihD-v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`linear_kernel`** took a smaller amount of time to execute. When you're working with a very large amount of data and your vectors are in the tf-idf representation, it is good practice to default to **`linear_kernel`** to improve performance. (NOTE: In case, you see **`linear_kernel`** taking more time, it's because the dataset we're dealing with is extremely small and Python's **`time`** module is incapable of capture such minute time differences accurately)\n",
        "\n",
        "## ***Plot recommendation engine***\n",
        "\n",
        "Build a recommendation engine that suggests movies based on similarity of plot lines. You have been given a `get_recommendations()` function that takes in the title of a movie, a similarity matrix and an `indices` series as its arguments and outputs a list of most similar movies. `indices` has already been provided to you.\n",
        "\n",
        "\n",
        "```\n",
        "title\n",
        "The Dark Knight Rises                     0\n",
        "Batman Forever                            1\n",
        "Batman                                    2\n",
        "Batman Returns                            3\n",
        "Batman & Robin                            4\n",
        "                                       ... \n",
        "Glory                                  1003\n",
        "Rosencrantz & Guildenstern Are Dead    1004\n",
        "Manhattan                              1005\n",
        "Miller's Crossing                      1006\n",
        "Dead Poets Society                     1007\n",
        "Length: 1008, dtype: int64\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You have also been given a `movie_plots` Series\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "0    Following the death of District Attorney Harve...\n",
        "1    The Dark Knight of Gotham City confronts a das...\n",
        "2    The Dark Knight of Gotham City begins his war ...\n",
        "3    Having defeated the Joker, Batman now faces th...\n",
        "4    Along with crime-fighting partner Robin and ne...\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        " that contains the plot lines of several movies. Your task is to generate a cosine similarity matrix for the tf-idf vectors of these plots.\n",
        "\n",
        "Consequently, we will check the potency of our engine by generating recommendations for one of my favorite movies, The Dark Knight Rises.\n",
        "\n",
        "- Initialize a **`TfidfVectorizer`** with English `stop_words`. Name it `tfidf`.\n",
        "- Construct `tfidf_matrix` by fitting and transforming the movie plot data using **`fit_transform()`**.\n",
        "- Generate the cosine similarity matrix `cosine_sim` using `tfidf_matrix`. Don't use **`cosine_similarity()`**!\n",
        "- Use `get_recommendations()` to generate recommendations for `'The Dark Knight Rises'`."
      ],
      "metadata": {
        "id": "oWzr6GBcMFho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(title, cosine_sim, indices):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "    # Get the pairwsie similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    # Get the scores for 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    # Return the top 10 most similar movies\n",
        "    return metadata['title'].iloc[movie_indices]  \n",
        "\n",
        "# Initialize the TfidfVectorizer \n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Construct the TF-IDF matrix\n",
        "tfidf_matrix = tfidf.fit_transform(movie_plots)\n",
        "\n",
        "# Generate the cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        " \n",
        "# Generate recommendations \n",
        "print(get_recommendations('The Dark Knight Rises', cosine_sim, indices))"
      ],
      "metadata": {
        "id": "wme7p0SXNryi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    1                              Batman Forever\n",
        "    2                                      Batman\n",
        "    3                              Batman Returns\n",
        "    8                  Batman: Under the Red Hood\n",
        "    9                            Batman: Year One\n",
        "    10    Batman: The Dark Knight Returns, Part 1\n",
        "    11    Batman: The Dark Knight Returns, Part 2\n",
        "    5                Batman: Mask of the Phantasm\n",
        "    7                               Batman Begins\n",
        "    4                              Batman & Robin\n",
        "    Name: title, dtype: object\n",
        "```\n",
        "\n",
        "Notice how the recommender correctly identifies 'The Dark Knight Rises' as a Batman movie and recommends other Batman movies as a result. This sytem is, of course, very primitive and there are a host of ways in which it could be improved. One method would be to look at the cast, crew and genre in addition to the plot to generate recommendations. We will not be covering this in this course but you have all the tools necessary to accomplish this.\n",
        "\n",
        "## ***The recommender function***\n",
        "\n",
        "In this exercise, we will build a recommender function `get_recommendations()`, as discussed in the lesson and the previous exercise. As we know, it takes in a title, a cosine similarity matrix, and a movie title and index mapping as arguments and outputs a list of 10 titles most similar to the original title (excluding the title itself).\n",
        "\n",
        "You have been given a dataset `metadata` that consists of the movie titles and overviews. The head of this dataset has been printed to console.\n",
        "\n",
        "\n",
        "```\n",
        "               title                                            tagline\n",
        "938  Cinema Paradiso  A celebration of youth, friendship, and the ev...\n",
        "630         Spy Hard  All the action. All the women. Half the intell...\n",
        "682        Stonewall                    The fight for the right to love\n",
        "514           Killer                    You only hurt the one you love.\n",
        "365    Jason's Lyric                                   Love is courage.\n",
        ".......\n",
        ".......\n",
        "```\n",
        "\n",
        "\n",
        "- Get index of the movie that matches the title by using the `title` key of `indices`.\n",
        "- Extract the ten most similar movies from `sim_scores` and store it back in `sim_scores`."
      ],
      "metadata": {
        "id": "JHNxiczgO0Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate mapping between titles and index\n",
        "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()"
      ],
      "metadata": {
        "id": "dXh9L2oiQChE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "title\n",
        "Cinema Paradiso              938\n",
        "Spy Hard                     630\n",
        "Stonewall                    682\n",
        "Killer                       514\n",
        "Jason's Lyric                365\n",
        "   ....                         ... \n",
        "Bottle Rocket                106\n",
        "Natural Born Killers         270\n",
        "Normal Life                  860\n",
        "In the Name of the Father    435\n",
        "La Haine                     102\n",
        "Length: 1008, dtype: int64\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "c642LoxBQbRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate mapping between titles and index\n",
        "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
        "\n",
        "def get_recommendations(title, cosine_sim, indices):\n",
        "    # Get index of movie that matches title\n",
        "    idx = indices[title]\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    # Get the scores for 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    # Return the top 10 most similar movies\n",
        "    return metadata['title'].iloc[movie_indices]"
      ],
      "metadata": {
        "id": "FrCfUkTJQdmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this recommender function in our toolkit, we are now in a very good place to build the rest of the components of our recommendation engine.\n",
        "\n",
        "## ***TED talk recommender***\n",
        "\n",
        "Build a recommendation system that suggests TED Talks based on their transcripts. You have been given a `get_recommendations()` function that takes in the title of a talk, a similarity matrix and an `indices` \n",
        "\n",
        "```\n",
        "title\n",
        "10 top time-saving tech tips                                                  0\n",
        "Who am I? Think again                                                         1\n",
        "\"Awoo\"                                                                        2\n",
        "What I learned from 2,000 obituaries                                          3\n",
        "Why giving away our wealth has been the most satisfying thing we've done      4\n",
        "                                                                           ... \n",
        "How to find work you love                                                   494\n",
        "Why you will fail to have a great career                                    495\n",
        "The puzzle of motivation                                                    496\n",
        "Plug into your hard-wired happiness                                         497\n",
        "The surprising habits of original thinkers                                  498\n",
        "Length: 499, dtype: int64\n",
        "```\n",
        "\n",
        "series as its arguments, and outputs a list of most similar talks. `indices` has already been provided to you.\n",
        "\n",
        "You have also been given a `transcripts`\n",
        "\n",
        "```\n",
        "\n",
        "0      I've noticed something interesting about socie...\n",
        "1      Hetain Patel: (In Chinese)Yuyu Rau: Hi, I'm He...\n",
        "2      (Music)Sophie Hawley-Weld: OK, you don't have ...\n",
        "3      Joseph Keller used to jog around the Stanford ...\n",
        "4      Chris Anderson: So, this is an interview with ...\n",
        "                             ...                        \n",
        "494    Wow, what an honor. I always wondered what thi...\n",
        "495    I want to discuss with you this afternoon why ...\n",
        "496    I need to make a confession at the outset here...\n",
        "497    I have a vision for each one of you, and the v...\n",
        "498    Seven years ago, a student came to me and aske...\n",
        "Name: transcript, Length: 499, dtype: object\n",
        "```\n",
        "\n",
        " series that contains the transcripts of around 500 TED talks. Your task is to generate a cosine similarity matrix for the tf-idf vectors of the talk `transcripts`.\n",
        "\n",
        "Consequently, we will generate recommendations for a talk titled `'5 ways to kill your dreams'` by Brazilian entrepreneur Bel Pesce.\n",
        "\n",
        "- Initialize a **`TfidfVectorizer`** with English `stopwords`. Name it `tfidf`.\n",
        "- Construct `tfidf_matrix` by fitting and transforming `transcripts`.\n",
        "- Generate the cosine similarity matrix `cosine_sim` using `tfidf_matrix`.\n",
        "- Use `get_recommendations()` to generate recommendations for `'5 ways to kill your dreams'`."
      ],
      "metadata": {
        "id": "jazw7D4_Rwdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TfidfVectorizer \n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Construct the TF-IDF matrix\n",
        "tfidf_matrix = tfidf.fit_transform(transcripts)\n",
        "\n",
        "# Generate the cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        " \n",
        "# Generate recommendations \n",
        "print(get_recommendations('5 ways to kill your dreams', cosine_sim, indices))"
      ],
      "metadata": {
        "id": "e6NYUpffSo8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "    453             Success is a continuous journey\n",
        "    157                        Why we do what we do\n",
        "    494                   How to find work you love\n",
        "    149          My journey into movies that matter\n",
        "    447                        One Laptop per Child\n",
        "    230             How to get your ideas to spread\n",
        "    497         Plug into your hard-wired happiness\n",
        "    495    Why you will fail to have a great career\n",
        "    179             Be suspicious of simple stories\n",
        "    53                          To upgrade is human\n",
        "    Name: title, dtype: object\n",
        "```\n",
        "\n",
        "You have successfully built a TED talk recommender. This recommender works surprisingly well despite being trained only on a small subset of TED talks.\n",
        "\n",
        "# **Word embeddings**\n",
        "\n",
        "- `'I am happy'`, `'I am joyous'`, `'I am sad'` have the same similarities\n",
        "- Word embeddings can detect synonyms and antonyms\n",
        "- Captures complex relationships \n",
        "   - `King` - `Queen` → `Man` - `Woman`\n",
        "   - `France` - `Paris` → `Russia` - `Moscow`\n"
      ],
      "metadata": {
        "id": "Sriw9UBHTlUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Generating word vectors***\n",
        "\n",
        "In this exercise, we will generate the pairwise similarity scores of all the words in a sentence. The sentence is available as `sent`.\n",
        "\n",
        "- Create a Doc object `doc` for `sent`.\n",
        "- In the nested loop, compute the similarity between `token1` and `token2`."
      ],
      "metadata": {
        "id": "9bcUVhn8QZvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'I like apples and oranges'\n",
        "\n",
        "# Create the doc object\n",
        "doc = nlp(sent)\n",
        "\n",
        "# Compute pairwise similarity scores\n",
        "for token1 in doc:\n",
        "    for token2 in doc:\n",
        "        print(token1.text, token2.text, token1.similarity(token2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJQlKbXQPr5e",
        "outputId": "6038b483-3a7f-4e2c-e3cc-e1e28c9eb9ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I I 1.0\n",
            "I like 0.3184410631656647\n",
            "I apples 0.1975560337305069\n",
            "I and -0.0979200005531311\n",
            "I oranges 0.05048730596899986\n",
            "like I 0.3184410631656647\n",
            "like like 1.0\n",
            "like apples 0.29574331641197205\n",
            "like and 0.24359610676765442\n",
            "like oranges 0.2706858515739441\n",
            "apples I 0.1975560337305069\n",
            "apples like 0.29574331641197205\n",
            "apples apples 1.0\n",
            "apples and 0.24472734332084656\n",
            "apples oranges 0.7808241248130798\n",
            "and I -0.0979200005531311\n",
            "and like 0.24359610676765442\n",
            "and apples 0.24472734332084656\n",
            "and and 1.0\n",
            "and oranges 0.3738573491573334\n",
            "oranges I 0.05048730596899986\n",
            "oranges like 0.2706858515739441\n",
            "oranges apples 0.7808241248130798\n",
            "oranges and 0.3738573491573334\n",
            "oranges oranges 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Notice how the words `'apples'` and `'oranges'` have the highest pairwaise similarity score. This is expected as they are both fruits and are more related to each other than any other pair of words.\n",
        "\n",
        " ## ***Computing similarity of Pink Floyd songs***\n",
        "\n",
        "In this final exercise, you have been given lyrics of three songs by the British band Pink Floyd, namely `'High Hopes'`, `'Hey You'` and `'Mother'`. The lyrics to these songs are available as `hopes`, `hey` and `mother` respectively.\n",
        "\n",
        "Your task is to compute the pairwise similarity between `mother` and `hopes`, and `mother` and `hey`.\n",
        "\n",
        "- Create Doc objects for `mother`, `hopes` and `hey`.\n",
        "- Compute the similarity between `mother` and `hopes`.\n",
        "- Compute the similarity between `mother` and `hey`."
      ],
      "metadata": {
        "id": "AaP1EUXlV2PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Doc objects\n",
        "mother_doc = nlp(mother)\n",
        "hopes_doc = nlp(hopes)\n",
        "hey_doc = nlp(hey)\n",
        "\n",
        "# Print similarity between mother and hopes\n",
        "print(mother_doc.similarity(hopes_doc))\n",
        "\n",
        "# Print similarity between mother and hey\n",
        "print(mother_doc.similarity(hey_doc))"
      ],
      "metadata": {
        "id": "h0MluViPVw6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "<script.py> output:\n",
        "    0.39086024058636387\n",
        "    0.8043758566468613\n",
        "```\n",
        "\n",
        "Notice that 'Mother' and 'Hey You' have a similarity score of 0.9 whereas 'Mother' and 'High Hopes' has a score of only 0.6. This is probably because 'Mother' and 'Hey You' were both songs from the same album 'The Wall' and were penned by Roger Waters. On the other hand, 'High Hopes' was a part of the album 'Division Bell' with lyrics by David Gilmour and his wife, Penny Samson. Treat yourself by listening to these songs. They're some of the best!\n",
        "\n"
      ],
      "metadata": {
        "id": "U1gsurVjW22u"
      }
    }
  ]
}