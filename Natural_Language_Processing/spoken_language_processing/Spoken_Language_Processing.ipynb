{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PYyJyViEmmry",
        "outputId": "9b34a11c-d47e-47ab-d4c6-f9b13db79a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 15.2 MB/s \n",
            "\u001b[?25hCollecting PyICU\n",
            "  Downloading PyICU-2.10.2.tar.gz (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 55.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Building wheels for collected packages: polyglot, PyICU, pycld2\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52580 sha256=91ab20027ec68552e3361a4998f4a7cf759052130312e9537357d6c52e1434e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/5e/19/5d7096ca9d067df54509d4bd382332e1babeef05715a13ac39\n",
            "  Building wheel for PyICU (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyICU: filename=PyICU-2.10.2-cp38-cp38-linux_x86_64.whl size=1396839 sha256=7e1b5a05aa77a6366af2c0a833bf399ffd95463f9943bea48e42b295262ba82c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/30/74/41fd0a7e2e17f8f92d5a4584c2aad30d8235c8cfa63a13742f\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp38-cp38-linux_x86_64.whl size=9833478 sha256=fdb3152c2c96cba93229909d3169c23e3ecc3222e011f39a056654752557a9a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/3a/82/d990040cbe6c3527732e931e2925785e83fe9aaa5a11c313ca\n",
            "Successfully built polyglot PyICU pycld2\n",
            "Installing collected packages: PyICU, pycld2, polyglot, morfessor\n",
            "Successfully installed PyICU-2.10.2 morfessor-2.0.6 polyglot-16.7.4 pycld2-0.41\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting simpleaudio\n",
            "  Downloading simpleaudio-1.0.4.tar.gz (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Building wheels for collected packages: simpleaudio\n",
            "  Building wheel for simpleaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simpleaudio: filename=simpleaudio-1.0.4-cp38-cp38-linux_x86_64.whl size=2063827 sha256=66b56f985e67b4e910b7310b8af4af43493563f92d87ae5eefaac89b33ce0239\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/46/0a/194e1db8ba343c98e075410186eba0b3bce3993062cdb0169d\n",
            "Successfully built simpleaudio\n",
            "Installing collected packages: requests, SpeechRecognition, simpleaudio, pydub\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed SpeechRecognition-3.9.0 pydub-0.25.1 requests-2.28.1 simpleaudio-1.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 17.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (7.1.2)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, contourpy, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed contourpy-1.0.6 fonttools-4.38.0 matplotlib-3.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install polyglot PyICU pycld2 morfessor\n",
        "!pip install SpeechRecognition pydub simpleaudio\n",
        "!pip install matplotlib --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt, numpy as np, seaborn as sns, pandas as pd, re, nltk, itertools, spacy, speech_recognition as sr\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"vader_lexicon\")\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize, TweetTokenizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tree import Tree\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "from polyglot.text import Text, Word\n",
        "from polyglot.downloader import downloader\n",
        "downloader.download(\"embeddings2.es\")\n",
        "downloader.download(\"ner2.es\")\n",
        "downloader.download(\"embeddings2.fr\")\n",
        "downloader.download(\"ner2.fr\")\n",
        "from collections import Counter, defaultdict\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_lg\n",
        "from spacy.lang.en import English\n",
        "from spacy.matcher import PhraseMatcher, Matcher\n",
        "from spacy.tokens import Doc, Span\n",
        "from spacy.language import Language\n",
        "from spacy.pipeline import EntityRuler\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2UOInPOmy9_",
        "outputId": "8bf02a65-68a8-4980-90a0-72e84a370765"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[polyglot_data] Downloading package embeddings2.es to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package ner2.es to /root/polyglot_data...\n",
            "[polyglot_data] Downloading package embeddings2.fr to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package ner2.fr to /root/polyglot_data...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-12 08:41:31.013624: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-12 08:41:43.532697: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.8 MB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-md==3.4.1) (3.4.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.28.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-12 08:41:57.225310: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 587.7 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-lg==3.4.1) (3.4.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.28.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Importing an audio file with Python***\n",
        "\n",
        "You've seen how there are different kinds of audio files and how streaming music and spoken language have different sampling rates. But now we want to start working with these files.\n",
        "\n",
        "To begin, we're going to import the `good_morning.wav` audio file using Python's in-built **`wave`** library. Then we'll see what it looks like in byte form using the built-in **`.readframes()`** method.\n",
        "\n",
        "You can listen to `good_morning.wav` [here](https://assets.datacamp.com/production/repositories/4637/datasets/d30b8e2319792fb3e9d7ce1e469b15ecf3f75227/good-morning.wav).\n",
        "\n",
        "Remember, `good_morning.wav` is only a few seconds long but at 48 kHz, that means it contains 48,000 pieces of information per second.\n",
        "\n",
        "* Import the Python `wave` library.\n",
        "* Read in the `good_morning.wav` audio file and save it to `good_morning`.\n",
        "* Create `signal_gm` by reading all the frames from `good_morning` using `readframes()`.\n",
        "* See what the first 10 frames of audio look like by slicing `signal_gm`."
      ],
      "metadata": {
        "id": "F0p5AgaqFtZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "\n",
        "# Create audio file wave object\n",
        "good_morning = wave.open('good_morning.wav', 'r')\n",
        "\n",
        "# Read all frames from wave object \n",
        "signal_gm = good_morning.readframes(-1)\n",
        "\n",
        "# View first 10\n",
        "print(signal_gm[:10])"
      ],
      "metadata": {
        "id": "eTgfai79nTuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309ce95a-42b3-428c-abbf-a4cb71c17b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xfd\\xff\\xfb\\xff\\xf8\\xff\\xf8\\xff\\xf7\\xff'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting bytes to integers**"
      ],
      "metadata": {
        "id": "hPqbbeL0TbeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert soundwave_gm from bytes to integers\n",
        "soundwave_gm = np.frombuffer(signal_gm, dtype='int16')\n",
        "\n",
        "# Show the first 10 items\n",
        "soundwave_gm[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Wuk7lsHUY2",
        "outputId": "edc65f6e-07ba-48f9-e6b2-b6172eb4e5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -3,  -5,  -8,  -8,  -9, -13,  -8, -10,  -9, -11], dtype=int16)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finding the frame rate**\n",
        "\n",
        "- $\\text{Frequency (Hz)}$ = $\\frac{\\text{length of wave object array}}{\\text{duration of audio file (seconds)}}$"
      ],
      "metadata": {
        "id": "mMgP6F8wUI3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the frame rate\n",
        "framerate_gm = good_morning.getframerate()\n",
        "\n",
        "# Show the frame rate\n",
        "framerate_gm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHoFk1f1TqIo",
        "outputId": "733cf18a-1ad0-4d6d-ac4b-9f97121653b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finding sound wave timestamps**"
      ],
      "metadata": {
        "id": "uQ5OQSjaVBMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the timestamps of the good morning sound wave\n",
        "time_gm = np.linspace(start=0, # จุดเริ่มของไฟล์เสียง\n",
        "                      stop=len(soundwave_gm)/framerate_gm, # ระยะเวลาของไฟล์เสียง\n",
        "                      num=len(soundwave_gm)) \n",
        "time_gm[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPqonzTUyha",
        "outputId": "e69298e3-65d5-4129-a6ec-b323e6bc1e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 2.08334167e-05, 4.16668333e-05, 6.25002500e-05,\n",
              "       8.33336667e-05, 1.04167083e-04, 1.25000500e-04, 1.45833917e-04,\n",
              "       1.66667333e-04, 1.87500750e-04])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตัวเลขใน array ข้างบน แสดงถึงช่วงเวลาเป็นวินาที เมื่อแต่ละ sound wave เกิดขึ้น"
      ],
      "metadata": {
        "id": "b4x7Jl0WWASr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Processing audio data with Python***\n",
        "\n",
        "You've seen how a sound waves can be turned into numbers but what does all that conversion look like?\n",
        "\n",
        "And how about another similar sound wave? One slightly different?\n",
        "\n",
        "Use MatPlotLib to plot the sound wave of `good_morning` against `good_afternoon`.\n",
        "\n",
        "To have the `good_morning` and `good_afternoon` sound waves on the same plot and distinguishable from each other, we'll use MatPlotLib's `alpha` parameter.\n",
        "\n",
        "- Set the title to reflect the plot we are making.\n",
        "- Add the `good_afternoon` time variable (`time_ga`) and amplitude variable (`soundwave_ga`) to the plot.\n",
        "- Do the same with the good_morning time variable (`time_gm`) and amplitude variable (`soundwave_gm`) to the plot.\n",
        "- Set the `alpha` variable to 0.5."
      ],
      "metadata": {
        "id": "bvbECcnwazw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "good_afternoon = wave.open('good_afternoon.wav', 'r')\n",
        "signal_ga = good_afternoon.readframes(-1)\n",
        "soundwave_ga = np.frombuffer(signal_ga, dtype='int16')\n",
        "framerate_ga = good_afternoon.getframerate()\n",
        "time_ga = np.linspace(start=0, # จุดเริ่มของไฟล์เสียง\n",
        "                      stop=len(soundwave_ga)/framerate_ga, # ระยะเวลาของไฟล์เสียง\n",
        "                      num=len(soundwave_ga)) \n",
        "\n",
        "# Setup the title and axis titles\n",
        "plt.title('Good Afternoon vs. Good Morning')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlabel('Time (seconds)')\n",
        "\n",
        "# Add the Good Afternoon data to the plot\n",
        "plt.plot(time_ga, soundwave_ga, label='Good Afternoon')\n",
        "\n",
        "# Add the Good Morning data to the plot\n",
        "plt.plot(time_gm, soundwave_gm, label='Good Morning', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0kUYCL4nVexm",
        "outputId": "7bd12273-ab31-4658-d480-421f00e011a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the two sound waves are very similar in the beginning. Because the first word is \"good\" in both audio files, they almost completely overlap. A well-built speech recognition system would recognize this and return the same first word for each wave. Let's build one to do just that.\n",
        "\n",
        "# **Getting started with SpeechRecognition**"
      ],
      "metadata": {
        "id": "YHSDfqa4dBJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkkK-PQNc5P7",
        "outputId": "26ac570b-9698-4eda-b74b-6441118739c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 114 kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the Recognizer class**"
      ],
      "metadata": {
        "id": "T7SkkDTeitFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Create an instance of Recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Set the energy threshold\n",
        "recognizer.energy_threshold = 300 # ค่าต่ำกว่า 300 คือ ตีความเท่ากับไมมีเสียง"
      ],
      "metadata": {
        "id": "9qteJif-igNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recognize Speech**"
      ],
      "metadata": {
        "id": "NDQbmfS5jPjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Transcribe speech using Goole web API\n",
        "recognizer.recognize_google(audio_data=audio_file, language=\"en-US\")"
      ],
      "metadata": {
        "id": "k07pjz9FjSfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Learning speech recognition on DataCamp is awesome!\n",
        "```\n",
        "\n",
        "## ***Using the Recognizer class***\n",
        "\n",
        "Now you've created an instance of the **`Recognizer`** class we'll use the **`.recognize_google()`** method on it to access the Google web speech API and turn spoken language into text.\n",
        "\n",
        "**`recognize_google()`** requires an argument `audio_data` otherwise it will return an error.\n",
        "\n",
        "US English is the default language. If your audio file isn't in US English, you can change the language with the `language` argument. A list of language codes can be seen [here](https://cloud.google.com/speech-to-text/docs/languages).\n",
        "\n",
        "An audio file containing English speech has been imported as `clean_support_call`. You can listen to the audio file [here](https://assets.datacamp.com/production/repositories/4637/datasets/393a2f76d057c906de27ec57ea655cb1dc999fce/clean-support-call.wav). SpeechRecognition has also been imported as `sr`.\n",
        "\n",
        "To avoid hitting the API request limit of Google's web API, we've mocked the **`Recognizer`** class to work with our audio files. This means some functionality will be limited.\n",
        "\n",
        "\n",
        "- Call the **`recognize_google()`** method on `recognizer` and pass it `clean_support_call`.\n",
        "- Set the language argument to \"en-US\".\n",
        "\n",
        "- *ขั้นตอนต่อไปนี้ ต้องใส่เพิ่มเข้ามาเองในการสร้างไฟล์เสียงที่ใช้กับ `.recognize_google()`*\n",
        "\n",
        "\n",
        "```\n",
        "sound = sr.AudioFile('clean_support_call.wav')\n",
        "with sound as source:\n",
        "    clean_support_call = recognizer.record(sound)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ql98zDSfkEpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Create a recognizer class\n",
        "recognizer = sr.Recognizer()\n",
        "sound = sr.AudioFile('clean_support_call.wav')\n",
        "with sound as source:\n",
        "    clean_support_call = recognizer.record(sound)\n",
        "\n",
        "# Transcribe the support call audio\n",
        "text = recognizer.recognize_google(audio_data=clean_support_call,\n",
        "                                   language=\"en-US\")\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyaGp78mceh",
        "outputId": "45d5cb2f-a774-43d0-8362-1146e1e40b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.987629,\n",
            "                           'transcript': \"hello I'd like to get some help \"\n",
            "                                         'setting up my account please'}],\n",
            "    'final': True}\n",
            "hello I'd like to get some help setting up my account please\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You just transcribed your first piece of audio using `speech_recognition`'s **`Recognizer`** class! Well, we've set it a mock version of **`Recognizer`** so we don't hit the API max requests limit. Notice how the `'hello'` wasn't seperate from the rest of the text. As powerful as **`recognize_google()`** is, it doesn't have sentence separation.\n",
        "\n",
        "# **Reading audio files with SpeechRecognition**\n",
        "## **The AudioFile class**\n",
        "\n"
      ],
      "metadata": {
        "id": "gdDFcjUtm1XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Setup recognizer instance\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Read in audio file\n",
        "clean_support_call = sr.AudioFile(\"clean_support_call.wav\")\n",
        "\n",
        "# Check type of clean_support_call\n",
        "type(clean_support_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrgb_8i3mhRP",
        "outputId": "85519acc-f371-4ee1-f9c8-6d46878cdd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speech_recognition.AudioFile"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **From `AudioFile` to `AudioData`**"
      ],
      "metadata": {
        "id": "ebzvB0b4tjjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from AudioFile to AudioData\n",
        "with clean_support_call as source:\n",
        "    clean_support_call_audio = recognizer.record(source)\n",
        "\n",
        "type(clean_support_call_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V2s7hcctTnE",
        "outputId": "affce1d2-7fbc-48a6-d4a5-e3b91f92703b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speech_recognition.AudioData"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transcribing `AudioData`**"
      ],
      "metadata": {
        "id": "HWB3ejSEunL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recognizer.recognize_google(audio_data=clean_support_call_audio, language='en-US')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "GQoBR8IwtyM_",
        "outputId": "afcb840a-01f3-402e-afca-70cc62319820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.987629,\n",
            "                           'transcript': \"hello I'd like to get some help \"\n",
            "                                         'setting up my account please'}],\n",
            "    'final': True}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hello I'd like to get some help setting up my account please\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Duration and offset**"
      ],
      "metadata": {
        "id": "vw5de9uJvHHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get first 1-second of clean support call\n",
        "with clean_support_call as source:\n",
        "    clean_support_call_audio = recognizer.record(source, duration=1.0)\n",
        "\n",
        "recognizer.recognize_google(audio_data=clean_support_call_audio, language='en-US')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "vBVsgY6Cu1RE",
        "outputId": "b0b1f622-5bf3-4a1d-9bf0-b58df1e4aea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [{'confidence': 0.98762906, 'transcript': 'hello'}],\n",
            "    'final': True}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Recording the audio we need***\n",
        "\n",
        "Sometimes you may not want the entire audio file you're working with. The `duration` and `offset` parameters of the **`.record()`** method can help with this.\n",
        "\n",
        "After exploring your dataset, you find there's one file, imported as `nothing_at_end` which has [30-seconds of silence at the end](https://assets.datacamp.com/production/repositories/4637/datasets/ca799cf2a7b093c06e1a5ae1dd96a49d48d65efa/30-seconds-of-nothing-16k.wav) and a support call file, imported as `out_of_warranty` has [3-seconds of static at the front](https://assets.datacamp.com/production/repositories/4637/datasets/dbc47d8210fdf8de42b0da73d1c2ba92e883b2d2/static-out-of-warranty.wav).\n",
        "\n",
        "Setting `duration` and `offset` means the **`.record()`** method will record up to `duration` audio starting at `offset`. They're both measured in seconds.\n",
        "\n",
        "- Let's get the first 10-seconds of `nothing_at_end_audio`. To do this, you can set duration to 10."
      ],
      "metadata": {
        "id": "4MSN0JtyxC1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nothing_at_end = sr.AudioFile(\"30-seconds-of-nothing-16k.wav\")\n",
        "\n",
        "# Convert AudioFile to AudioData\n",
        "with nothing_at_end as source:\n",
        "    nothing_at_end_audio = recognizer.record(source, duration=10.0, offset=None)\n",
        "\n",
        "# Transcribe AudioData to text\n",
        "text = recognizer.recognize_google(nothing_at_end_audio, language=\"en-US\")\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WJhgfxrvXK6",
        "outputId": "015db7d1-36b4-4d3d-908a-d9bb18ab3db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.88164651,\n",
            "                           'transcript': 'this ODI fall has 30 seconds of '\n",
            "                                         'nothing at the end of it'},\n",
            "                       {   'transcript': 'this audio fall has 30 seconds of '\n",
            "                                         'nothing at the end of it'},\n",
            "                       {   'transcript': 'this audiophile has 30 seconds of '\n",
            "                                         'nothing at the end of it'},\n",
            "                       {   'transcript': 'this ODI fall has thirty seconds of '\n",
            "                                         'nothing at the end of it'},\n",
            "                       {   'transcript': 'this audio file has 30 seconds of '\n",
            "                                         'nothing at the end of it'}],\n",
            "    'final': True}\n",
            "this ODI fall has 30 seconds of nothing at the end of it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's remove the first 3-seconds of static of `static_at_start` by setting `offset` to 3."
      ],
      "metadata": {
        "id": "BpPjdwb1yuQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "static_at_start = sr.AudioFile(\"static-out-of-warranty.wav\")\n",
        "\n",
        "# Convert AudioFile to AudioData\n",
        "with static_at_start as source:\n",
        "    static_art_start_audio = recognizer.record(source,duration=None,offset=3.0)\n",
        "\n",
        "# Transcribe AudioData to text\n",
        "text = recognizer.recognize_google(static_art_start_audio, language='en-US')\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toKvY0O3yhbO",
        "outputId": "86831a0d-7870-44d5-aa1f-b3e06aa03076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.94255513,\n",
            "                           'transcript': \"hello I'd like to get some help with \"\n",
            "                                         \"my device please I think it's out of \"\n",
            "                                         'warranty I bought it about 2 years '\n",
            "                                         'ago'},\n",
            "                       {   'transcript': \"hello I'd like to get some help with \"\n",
            "                                         \"my device please I think it's out of \"\n",
            "                                         'warranty I bought it about two years '\n",
            "                                         'ago'},\n",
            "                       {   'transcript': \"hello I'd like to get some help with \"\n",
            "                                         \"my device please I think it's \"\n",
            "                                         'out-of-warranty I bought it about 2 '\n",
            "                                         'years ago'},\n",
            "                       {   'transcript': \"hello I'd like to get some help with \"\n",
            "                                         \"my device please I think it's \"\n",
            "                                         'out-of-warranty I bought it about '\n",
            "                                         'two years ago'}],\n",
            "    'final': True}\n",
            "hello I'd like to get some help with my device please I think it's out of warranty I bought it about 2 years ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speech recognition can be resource intensive, so in practice, you'll want to explore your audio files to make you're not wasting any computing power trying to transcribe static or silence.\n",
        "\n",
        "# **Non-speech audio**\n",
        "\n"
      ],
      "metadata": {
        "id": "bt_XJYNOzgUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "leopard_roar = sr.AudioFile(\"leopard_roar.wav\")\n",
        "with leopard_roar as source:\n",
        "    leopard_roar_audio = recognizer.record(source)\n",
        "recognizer.recognize_google(leopard_roar_audio)"
      ],
      "metadata": {
        "id": "Y-HcGTbszKTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "UnknownValueError:\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cOVSAVyQlD-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Showing all**"
      ],
      "metadata": {
        "id": "aDMUYG74l8E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recognizing Japanese audio with show_all=True\n",
        "text = recognizer.recognize_google(japanese_good_morning, language=\"en-US\",\n",
        "                                   show_all=True)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "MnoULC48lFYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'alternative': [{'transcript': 'Ohio gozaimasu', 'confidence': 0.89041114},\n",
        "{'transcript': 'all hail gozaimasu'},\n",
        "{'transcript': 'ohayo gozaimasu'},\n",
        "{'transcript': 'olho gozaimasu'},\n",
        "{'transcript': 'all Hale gozaimasu'}],\n",
        "'final': True}\n",
        "```\n",
        "\n",
        "# **Multiple speakers**\n",
        "\n",
        "-  manually split the audio file into different speakers\n",
        "\n"
      ],
      "metadata": {
        "id": "mdKfTBjtmD6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import audio files separately\n",
        "speakers = [sr.AudioFile(\"s0.wav\"), sr.AudioFile(\"s1.wav\"), sr.AudioFile(\"s2.wav\")]\n",
        "\n",
        "# Transcribe each speaker individually\n",
        "for i, speaker in enumerate(speakers):\n",
        "    with speaker as source:\n",
        "        speaker_audio = recognizer.record(source)\n",
        "    print(f\"Text from speaker {i}: {recognizer.recognize_google(speaker_audio)}\")"
      ],
      "metadata": {
        "id": "WrIOGj6YmbCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Text from speaker 0: one of the limitations of the speech recognition library\n",
        "Text from speaker 1: is that it doesn't recognise different speakers and voices\n",
        "Text from speaker 2: it will just return it all as one block a text\n",
        "```\n",
        "\n",
        "# **Noisy audio**\n",
        "\n",
        "- If you have trouble hearing the speech, so will the APIs\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8LfIl95mjDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import audio file with background nosie\n",
        "noisy_support_call = sr.AudioFile('noisy_support_call.wav')\n",
        "\n",
        "with noisy_support_call as source:\n",
        "    # Adjust for ambient noise and record\n",
        "    recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
        "    noisy_support_call_audio = recognizer.record(source)\n",
        "    \n",
        "# Recognize the audio\n",
        "recognizer.recognize_google(noisy_support_call_audio)"
      ],
      "metadata": {
        "id": "ye-g0wmSmtmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Different languages***\n",
        "\n",
        "Now you've seen an example of how the **`Recognizer`** class works. Let's try a few more. How about speech from a different language?\n",
        "\n",
        "What do you think will happen when we call the **`recognize_google()`** function on a[ Japanese version of good_morning.wav](https://assets.datacamp.com/production/repositories/4637/datasets/cd9b801670d0664275cdbd3a24b6b70a8c2e5222/good-morning-japanense.wav) (japanese_audio)?\n",
        "\n",
        "The default language is `\"en-US\"`, are the results the same with the `\"ja\"` tag?\n",
        "\n",
        "How about non-speech audio? Like this leopard roaring ([leopard_audio](https://assets.datacamp.com/production/repositories/4637/datasets/5720832b2735089d8e735cac3e0b0ad9b5114864/leopard.wav).\n",
        "\n",
        "Or speech where the sounds may not be real words, such as a [baby talking](https://assets.datacamp.com/production/repositories/4637/datasets/e9fd46a06d74431e3baa942c489e1b119d85a233/charlie-bit-me-5.wav) (`charlie_audio`)?\n",
        "\n",
        "To familiarize more with the **`Recognizer`** class, we'll look at an example of each of these."
      ],
      "metadata": {
        "id": "5JWcgDolnd7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "ohaiyo = sr.AudioFile('good-morning-japanense.wav')\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "with ohaiyo as source:\n",
        "    japanese_audio = recognizer.record(source)\n",
        "\n",
        "# Pass the Japanese audio to recognize_google\n",
        "text = recognizer.recognize_google(japanese_audio, language=\"en-US\")\n",
        "\n",
        "# Print the text\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HaC21L4oZ59",
        "outputId": "7c2478aa-c0ce-4520-9a58-856714b9887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.98762906,\n",
            "                           'transcript': 'ohayo gozaimasu'}],\n",
            "    'final': True}\n",
            "ohayo gozaimasu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pass the same Japanese audio (`japanese_audio`) using `\"ja\"` as the language parameter. Do you see a difference?"
      ],
      "metadata": {
        "id": "HdX6u7xSpNRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the Japanese audio to recognize_google\n",
        "text = recognizer.recognize_google(japanese_audio, language='ja')\n",
        "\n",
        "# Print the text\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bcC1Pwgo9y6",
        "outputId": "440d1366-2d91-4979-ef44-ea0386f64895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {'confidence': 0.9111861, 'transcript': 'おはようございます'},\n",
            "                       {'transcript': 'あおはようございます'},\n",
            "                       {'transcript': 'おはようございまーす'},\n",
            "                       {'transcript': 'あおはようございまーす'}],\n",
            "    'final': True}\n",
            "おはようございます\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What about about non-speech audio? Pass `leopard_audio` to **`recognize_google()`** with `show_all` as True."
      ],
      "metadata": {
        "id": "c0N4BikRpZSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roar = sr.AudioFile('leopard.wav')\n",
        "\n",
        "with roar as source:\n",
        "    leopard_audio = recognizer.record(source)\n",
        "\n",
        "# Pass the leopard roar audio to recognize_google\n",
        "text = recognizer.recognize_google(leopard_audio, \n",
        "                                   language=\"en-US\", \n",
        "                                   show_all=True)\n",
        "\n",
        "# Print the text\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H13mXDVnpVYc",
        "outputId": "548b46f1-b6f8-478a-aa5a-3b71936edf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What if your speech files have non-audible human sounds? Pass `charlie_audio` to **`recognize_google()`** to find out."
      ],
      "metadata": {
        "id": "LkUMbfXnp_Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baby = sr.AudioFile('charlie-bit-me-5.wav')\n",
        "\n",
        "with baby as source:\n",
        "    charlie_audio = recognizer.record(source)\n",
        "\n",
        "# Pass charlie_audio to recognize_google\n",
        "text = recognizer.recognize_google(charlie_audio, \n",
        "                                   language=\"en-US\")\n",
        "\n",
        "# Print the text\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl-5g6J7p8Bj",
        "outputId": "640ba279-0d7b-421a-89fa-ee41858253dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.34498742,\n",
            "                           'transcript': 'charlie bit me'},\n",
            "                       {'transcript': 'Charlie Batman'},\n",
            "                       {'transcript': 'Batman'},\n",
            "                       {'transcript': 'surely Batman'},\n",
            "                       {'transcript': 'Jolly Batman'}],\n",
            "    'final': True}\n",
            "charlie bit me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Import an audio file with PyDub***\n",
        "\n",
        "`PyDub`'s `AudioSegment` class makes it easy to import and manipulate audio files with Python.\n",
        "\n",
        "In this exercise, we'll import an audio file of interest by creating an instance of **`AudioSegment`**.\n",
        "\n",
        "To import an audio file, you can use the **`from_file()`** function on **`AudioSegment`** and pass it your target audio file's pathname as a string. The `format` parameter gives you an option to specify the format of your audio file, however, this is optional as **`PyDub`** will automatically infer it.\n",
        "\n",
        "**`PyDub`** works with `.wav` files without any extra dependencies but for other file types like `.mp3`, you'll need to install **`ffmpeg`**.\n",
        "\n",
        "A sample audio file has been setup as `wav_file.wav`, you can listen to it [here](https://assets.datacamp.com/production/repositories/4637/datasets/6238f8088db33efb5d103dfac1e42eb9fe3e6f2b/wav_file.wav).\n",
        "\n",
        "\n",
        "- Import **`AudioSegment`** from **`pydub`**.\n",
        "- Call the **`from_file`** method and pass it the audio file pathname."
      ],
      "metadata": {
        "id": "Aw7kVVnmuT1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import AudioSegment from Pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Create an AudioSegment instance\n",
        "wav_file = AudioSegment.from_file(file='wav_file.wav', format=\"wav\")\n",
        "\n",
        "# Check the type\n",
        "print(type(wav_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZLiNGEdttGn",
        "outputId": "81ff994c-affb-414b-f2d8-38309ffc0679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pydub.audio_segment.AudioSegment'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Play an audio file with PyDub***\n",
        "\n",
        "If you're working with audio files, chances are you want to listen to them.\n",
        "\n",
        "**`PyDub`**'s **`playback`** module provides a function called **`play()`** which can be passed an **`AudioSegment`**. Running the **`play()`** function with an **`AudioSegment`** passed in will play the **`AudioSegment`** out loud.\n",
        "\n",
        "This can be helpful to check the quality of your audio files and assess any changes you need to make.\n",
        "\n",
        "Remember: to use the **`play()`** function, you'll need **`simpleaudio`** or **`pyaudio`** installed for `.wav` files and **`ffmpeg`** for other kinds of files.\n",
        "\n",
        "\n",
        "- Import `play` from the **`pydub.playback`** module.\n",
        "- Call **`play()`** whilst passing it the `wav_file` **`AudioSegment`**."
      ],
      "metadata": {
        "id": "NKSFe7Bvv7el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import AudioSegment and play\n",
        "import simpleaudio\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "# Create an AudioSegment instance\n",
        "wav_file = AudioSegment.from_file(file=\"wav_file.wav\", format=\"wav\")\n",
        "\n",
        "# Play the audio file\n",
        "play(wav_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dRYZdqz4vv1I",
        "outputId": "03b7a53f-6342-4a89-f197-a3bba196e6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SimpleaudioError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSimpleaudioError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4ce001174395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Play the audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pydub/playback.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(audio_segment)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mplayback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_play_with_simpleaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mplayback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pydub/playback.py\u001b[0m in \u001b[0;36m_play_with_simpleaudio\u001b[0;34m(seg)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_play_with_simpleaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msimpleaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     return simpleaudio.play_buffer(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mnum_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/simpleaudio/shiny.py\u001b[0m in \u001b[0;36mplay_buffer\u001b[0;34m(audio_data, num_channels, bytes_per_sample, sample_rate)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     play_id = _sa._play_buffer(audio_data, num_channels, bytes_per_sample,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                sample_rate)\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPlayObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSimpleaudioError\u001b[0m: Error opening PCM device. -- CODE: -2 -- MSG: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Audio parameters with PyDub***\n",
        "\n",
        "Every audio file you work with will have a number of characteristics associated with them, such as, channels, frame rate (or sample rate), sample width and more.\n",
        "\n",
        "Knowing these parameters is useful to ensure your audio files are compatible with various API requirements for speech transcription.\n",
        "\n",
        "For example, many APIs recommend a minimum frame rate (`wav_file.frame_rate`) of 16,000 Hz.\n",
        "\n",
        "When you create an instance of **`AudioSegment`**, **`PyDub`** automatically infers these parameters from your audio files and saves them as attributes.\n",
        "\n",
        "In this exercise, we'll explore these attributes.\n",
        "\n",
        "- Find the `frame_rate` of `wav_file`.\n",
        "\n",
        "- Find the number of channels of `wav_file`.\n",
        "\n",
        "- Find the max amplitude of `wav_file`.\n",
        "\n",
        "- Find the length of `wav_file` in milliseconds."
      ],
      "metadata": {
        "id": "MKarcmIvzhfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import audio file\n",
        "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
        "\n",
        "# Find the frame rate\n",
        "print(wav_file.frame_rate)\n",
        "\n",
        "# Find the number of channels\n",
        "print(wav_file.channels)\n",
        "\n",
        "# Find the max amplitude\n",
        "print(wav_file.max)\n",
        "\n",
        "# Find the length\n",
        "print(len(wav_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j03p4sF3yG_-",
        "outputId": "18f75aed-0ac9-452d-ca44-d693b3a50854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000\n",
            "2\n",
            "8484\n",
            "3284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Adjusting audio parameters***\n",
        "\n",
        "During your exploratory data analysis, you may find some of the parameters of your audio files differ or are incompatible with speech recognition APIs.\n",
        "\n",
        "Don't worry, **`PyDub`** has built-in functionality which allows you to change various attributes.\n",
        "\n",
        "For example, you can set the frame rate of your audio file calling **`set_frame_rate()`** on your **`AudioSegment`** instance and passing it an integer of the desired frame rate measured in Hertz.\n",
        "\n",
        "- Create a new `wav_file` with a frame rate of 16,000 Hz and then check its frame rate.\n",
        "\n",
        "- Set the `wav_file` number of channels to 1 and then check the number of channels.\n",
        "\n",
        "\n",
        "- Print the sample width of` wav_file` and then set it to 1 and print it again."
      ],
      "metadata": {
        "id": "yUNQhehnFSc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import audio file\n",
        "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
        "\n",
        "# Create a new wav file with adjusted frame rate\n",
        "wav_file_16k = wav_file.set_frame_rate(16000)\n",
        "\n",
        "# Check the frame rate of the new wav file\n",
        "print(wav_file_16k.frame_rate)\n",
        "\n",
        "\n",
        "# Set number of channels to 1\n",
        "wav_file_1_ch = wav_file.set_channels(1)\n",
        "\n",
        "# Check the number of channels\n",
        "print(wav_file_1_ch.channels)\n",
        "\n",
        "# Print sample_width\n",
        "print(f\"Old sample width: {wav_file.sample_width}\")\n",
        "\n",
        "# Set sample_width to 1\n",
        "wav_file_sw_1 = wav_file.set_sample_width(1)\n",
        "\n",
        "# Check new sample_width\n",
        "print(f\"New sample width: {wav_file_sw_1.sample_width}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxQ4jPOJEkoz",
        "outputId": "6e75e876-a710-46d1-b76e-18c3691aa34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000\n",
            "1\n",
            "Old sample width: 2\n",
            "New sample width: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Turning it down... then up***\n",
        "\n",
        "Speech recognition works best on clean, audible speech. If your audio files are too quiet or too loud, it can hinder transcription.\n",
        "\n",
        "In this exercise, you'll see how to make an **`AudioSegment`** quieter or louder.\n",
        "\n",
        "Since the play() function won't play your changes in the DataCamp classroom.\n",
        "\n",
        "The baseline audio file, `volume_adjusted.wav` can be heard [here](https://assets.datacamp.com/production/repositories/4637/datasets/520b312f96433535f93656d9e6d61fdb10f5c517/volume_adjusted.wav).\n",
        "\n",
        "\n",
        "- Import `volume_adjusted.wav` and lower its volume by 60 dB and save it to a new variable `quiet_volume_adjusted`.\n",
        "\n",
        "- Import the target audio file, increase its volume by 15 dB and save it to the variable `louder_volume_adjusted`."
      ],
      "metadata": {
        "id": "8kYUp6M7IKSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Import audio file\n",
        "volume_adjusted = AudioSegment.from_file('volume_adjusted.wav')\n",
        "\n",
        "# Lower the volume by 60 dB\n",
        "quiet_volume_adjusted = volume_adjusted - 60\n",
        "\n",
        "# Increase the volume by 15 dB\n",
        "louder_volume_adjusted = volume_adjusted + 15"
      ],
      "metadata": {
        "id": "ispGe1kkGcOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Normalizing an audio file with PyDub***\n",
        "\n",
        "Sometimes you'll have audio files where the speech is loud in some portions and quiet in others. Having this variance in volume can hinder transcription.\n",
        "\n",
        "Luckily, **`PyDub`**'s effects module has a function called **`normalize()`** which finds the maximum volume of an **`AudioSegment`**, then adjusts the rest of the **`AudioSegment`** to be in proportion. This means the quiet parts will get a volume boost.\n",
        "\n",
        "You can listen to an example of an audio file which starts as loud then goes quiet, `loud_then_quiet.wav`, [here](https://assets.datacamp.com/production/repositories/4637/datasets/9251c751d3efccf781f3e189d68b37c8d22be9ca/ex3_datacamp_loud_then_quiet.wav).\n",
        "\n",
        "Use **`normalize()`** to normalize the volume of our file, making it sound more like this.\n",
        "\n",
        "- Import **`AudioSegment`** from **`PyDub`** and **`normalize`** from the **`PyDub`**'s effects module.\n",
        "\n",
        "- Import the target audio file, `loud_then_quiet.wav` and save it to `loud_then_quiet`.\n",
        "\n",
        "- Normalize the imported audio file using the **`normalize()`** function and save it to `normalized_loud_then_quiet`."
      ],
      "metadata": {
        "id": "AZRchmo7MiRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.effects import normalize\n",
        "\n",
        "# Import target audio file\n",
        "loud_then_quiet = AudioSegment.from_file('loud_then_quiet.wav')\n",
        "\n",
        "# Normalize target audio file\n",
        "normalized_loud_then_quiet = normalize(loud_then_quiet)"
      ],
      "metadata": {
        "id": "xBH6ag4VMFwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Chopping and changing audio files***\n",
        "\n",
        "Some of your audio files may have sections of redundancy. For example, you might find at the beginning of each file, there's a few seconds of static.\n",
        "\n",
        "Instead of trying to transcribe static, you can remove it.\n",
        "\n",
        "Since an **`AudioSegment`** is iterable, and measured in milliseconds, you can use slicing to alter the length.\n",
        "\n",
        "To get the first 3-seconds of `wav_file`, you'd use `wav_file[:3000]`.\n",
        "\n",
        "You can also add two **`AudioSegment`**'s together using the addition operator. This is helpful if you need to combine several audio files.\n",
        "\n",
        "To practice both of these, we're going to remove the first four seconds of [`part1.wav`](https://assets.datacamp.com/production/repositories/4637/datasets/6ef2e43497070fd23c6ce4c0fe1d9d0e46469750/ex3_slicing_part_1.wav), and add the remainder to [`part2.wav`](https://assets.datacamp.com/production/repositories/4637/datasets/3b47eb5ca2c696e816af04053150d96fd95b4c7f/ex3_slicing_part_2.wav). Leaving the end result sounding like [part_3.wav](https://assets.datacamp.com/production/repositories/4637/datasets/3803042506ed07d707fe264d0bc6ec6ffa891e63/ex3_slicing_part_3.wav).\n",
        "\n",
        "\n",
        "- Import `part_1.wav` and `part_2.wav` and save them to `part_1` and `part_2` respectively.\n",
        "- Remove the first 4-seconds of `part_1` using slicing and save the new audio to `part_1_removed`.\n",
        "- Add `part_1_removed` to `part_2` and save it to `part_3`.\n",
        "\n"
      ],
      "metadata": {
        "id": "wCPWrzUuOkPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Import part 1 and part 2 audio files\n",
        "part_1 = AudioSegment.from_file('part_1.wav')\n",
        "part_2 = AudioSegment.from_file('part_2.wav')\n",
        "\n",
        "# Remove the first four seconds of part 1\n",
        "part_1_removed = part_1[4000:]\n",
        "\n",
        "# Add the remainder of part 1 and part 2 together\n",
        "part_3 = part_1_removed + part_2"
      ],
      "metadata": {
        "id": "eankoQAWOe39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Splitting stereo audio to mono with PyDub***\n",
        "\n",
        "If you're trying to transcribe phone calls, there's a chance they've been recorded in stereo format, with one speaker on each channel.\n",
        "\n",
        "As you've seen, it's hard to transcribe an audio file with more than one speaker. One solution is to split the audio file with multiple speakers into single files with individual speakers.\n",
        "\n",
        "**`PyDub`**'s **`split_to_mono()`** function can help with this. When called on an **`AudioSegment`** recorded in stereo, it returns a list of two separate **`AudioSegment`**'s in mono format, one for each channel.\n",
        "\n",
        "In this exercise, you'll practice this by splitting this [stereo phone call](https://assets.datacamp.com/production/repositories/4637/datasets/810bb65e2e681e086e90bc2c6c2372bc4bd2cb52/ex3_stereo_call.wav) (`stereo_phone_call.wav`) recording into [channel 1](https://assets.datacamp.com/production/repositories/4637/datasets/0aa876f5cb924035481d7b786a3701624e86d1e7/ex3_stereo_call_channel_1.wav) and [channel 2](https://assets.datacamp.com/production/repositories/4637/datasets/2a16db969efc35186fe25ca45a4dbd506318a1cd/ex3_stereo_call_channel_2.wav). This separates the two speakers, allowing for easier transcription.\n",
        "\n",
        "- Import **`AudioSegment`** from **`pydub`**.\n",
        "- Create an **`AudioSegment`** instance `stereo_phone_call` with `stereo_phone_call.wav`.\n",
        "- Split `stereo_phone_call` into channels using **`split_to_mono()`** and check the channels of the resulting output.\n",
        "- Save each channel to new variables, `phone_call_channel_1` and `phone_call_channel_2`."
      ],
      "metadata": {
        "id": "UXUAM1sfUIBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import AudioSegment\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Import stereo audio file and check channels\n",
        "stereo_phone_call = AudioSegment.from_file('stereo_phone_call.wav')\n",
        "print(f\"Stereo number channels: {stereo_phone_call.channels}\")\n",
        "\n",
        "# Split stereo phone call and check channels\n",
        "channels = stereo_phone_call.split_to_mono()\n",
        "print(f\"Split number channels: {channels[0].channels}, {channels[1].channels}\")\n",
        "\n",
        "# Save new channels separately\n",
        "phone_call_channel_1 = channels[0]\n",
        "phone_call_channel_2 = channels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAqzwzrdUCrn",
        "outputId": "b6b98c90-ba53-46e6-e67d-6255a786a7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stereo number channels: 2\n",
            "Split number channels: 1, 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having audio files with only one speaker usually results in better quality transcriptions.\n",
        "\n",
        "## ***Exporting and reformatting audio files***\n",
        "\n",
        "If you've made some changes to your audio files, or if they've got the wrong file extension, you can use **`PyDub`** to export and save them as new audio files.\n",
        "\n",
        "You can do this by using the **`.export()`** function on any instance of an **`AudioSegment`** you've created. The **`export()`** function takes two parameters, `out_f`, or the destination file path of your audio file and format, the format you'd like your new audio file to be. Both of these are strings. format is `\"mp3\"` by default so be sure to change it if you need.\n",
        "\n",
        "Import [this](https://assets.datacamp.com/production/repositories/4637/datasets/b035eadbae1544450868436a7179fa70158eb5de/mp3_file.mp3) `.mp3` file (`mp3_file.mp3`) and then export it with the `.wav` extension using **`.export()`**.\n",
        "\n",
        "Remember, to work with files other than `.wav`, you'll need **`ffmpeg`**.\n",
        "\n",
        "- Import `mp3_file.mp3` and save it to `mp3_file`.\n",
        "- Export `mp3_file` with the file name `mp3_file.wav` with `\"wav\"` format."
      ],
      "metadata": {
        "id": "qIlyoR5JVpgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Import the .mp3 file\n",
        "mp3_file = AudioSegment.from_file('mp3_file.mp3')\n",
        "\n",
        "# Export the .mp3 file as wav\n",
        "mp3_file.export(out_f='mp3_file.wav', format='wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO9_8sO_VkIC",
        "outputId": "ccf52b8b-b9f7-4c3a-ea21-dbdb8c22dc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='mp3_file.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Manipulating multiple audio files with PyDub***\n",
        "\n",
        "You've seen how to convert a single file using PyDub but what if you had a folder with multiple different file types?\n",
        "\n",
        "For this exercise, we've setup a folder which has `.mp3`, `.m4a` and `.aac` versions of the `good-afternoon` audio file.\n",
        "\n",
        "We'll use PyDub to open each of the files and export them as `.wav` format so they're compatible with speech recognition APIs.\n",
        "\n",
        "- Pass `audio_file` to the **`from_file()`** function.\n",
        "- Use **`export()`** to export `wav_filename` with the format `\"wav\"`."
      ],
      "metadata": {
        "id": "J450L7fbttJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Loop through the files in the folder\n",
        "for audio_file in os.listdir('/content'):\n",
        "\n",
        "    if (str(audio_file)[0] != '.') :\n",
        "    \n",
        "        # Create the new .wav filename\n",
        "        wav_filename = os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
        "            \n",
        "        # Read audio_file and export it in wav format\n",
        "        AudioSegment.from_file(audio_file).export(out_f=wav_filename, format='wav')\n",
        "            \n",
        "        print(f\"Creating {wav_filename}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-YHjRRMtlpt",
        "outputId": "742632f4-56bd-4506-92d2-b2b9580668f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating volume_adjusted.wav...\n",
            "Creating mp3_file.wav...\n",
            "Creating part_2.wav...\n",
            "Creating mp3_file.wav...\n",
            "Creating stereo_phone_call.wav...\n",
            "Creating part_3.wav...\n",
            "Creating loud_then_quiet.wav...\n",
            "Creating part_1.wav...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***An audio processing workflow***\n",
        "\n",
        "You've seen how to import and manipulate a single audio file using PyDub. But what if you had a folder with multiple audio files you needed to convert?\n",
        "\n",
        "Use PyDub to format a folder of files to be ready to use with **`speech_recognition`**.\n",
        "\n",
        "You've found your customer call files all have 3-seconds of static at the start and are quieter than they could be.\n",
        "\n",
        "To fix this, we'll use PyDub to cut the static, increase the sound level and convert them to the `.wav` extension.\n",
        "\n",
        "You can listen to an unformatted example [here](https://assets.datacamp.com/production/repositories/4637/datasets/c53557fea60087064aec7e9d99e889b9be79e75a/ex3-static-help-with-account.mp3).\n",
        "\n",
        "\n",
        "- Let's start with one file. Import `account_help.mp3` and cut off the first 3-seconds (3000 milliseconds) of static.\n",
        "\n",
        "- Increase the volume by 10dB.\n",
        "\n"
      ],
      "metadata": {
        "id": "aYFg0v_ExXvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_with_static = AudioSegment.from_file(\"account_help.mp3\")\n",
        "\n",
        "# Cut the 3-seconds of static off\n",
        "file_without_static = file_with_static[3000:]\n",
        "\n",
        "# Increase the volume by 10dB\n",
        "louder_file_without_static = file_without_static + 10"
      ],
      "metadata": {
        "id": "V3b5sqzWvGkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now for multiple files. Use **`from_file()`** to import each `audio_file` and export the louder files without static with the `\"wav\"` format."
      ],
      "metadata": {
        "id": "qktPwd8YyOBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for audio_file in folder:\n",
        "    file_with_static = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    # Cut the 3-seconds of static off\n",
        "    file_without_static = file_with_static[3000:]\n",
        "\n",
        "    # Increase the volume by 10dB\n",
        "    louder_file_without_static = file_without_static + 10\n",
        "    \n",
        "    # Create the .wav filename for export\n",
        "    wav_filename = os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
        "    \n",
        "    # Export the louder file without static as .wav\n",
        "    louder_file_without_static.export(wav_filename, format='wav')\n",
        "    print(f\"Creating {wav_filename}...\")"
      ],
      "metadata": {
        "id": "IsL8OrbTygBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Converting audio to the right format***\n",
        "\n",
        "Acme Studios have asked you to do a proof of concept to find out more about their audio files.\n",
        "\n",
        "After exploring them briefly, you find there's a few calls but they're in the wrong file format for transcription.\n",
        "\n",
        "As you'll be interacting with many audio files, you decide to begin by creating some helper functions.\n",
        "\n",
        "The first one, `convert_to_wav(filename)` takes a file path and uses `PyDub` to convert it from a non-wav format to `.wav` format.\n",
        "\n",
        "Once it's built, we'll use the function to convert [Acme's first call](https://assets.datacamp.com/production/repositories/4637/datasets/83ef1650407e911a0f52f491068e3082661db743/ex4_call_1_stereo_mp3.mp3), `call_1.mp3`, from `.mp3` format to `.wav`.\n",
        "\n",
        "**`PyDub`**'s **`AudioSegment`** class has already been imported. Remember, to work with non-wav files, you'll need **[`ffmpeg](http://www.ffmpeg.org/)`**.\n",
        "\n",
        "- Import the filename parameter using **`AudioSegment`**'s **`from_file()`**.\n",
        "- Set the export format to `\"wav\"`.\n",
        "- Pass the target audio file, `call_1.mp3`, to the function."
      ],
      "metadata": {
        "id": "sTR-c1To3GDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Create function to convert audio file to wav\n",
        "def convert_to_wav(filename):\n",
        "    \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
        "    # Import audio file\n",
        "    audio = AudioSegment.from_file(filename)\n",
        "    \n",
        "    # Create new filename\n",
        "    new_filename = filename.split(\".\")[0] + \".wav\"\n",
        "    \n",
        "    # Export file as .wav\n",
        "    audio.export(new_filename, format='wav')\n",
        "    print(f\"Converting {filename} to {new_filename}...\")\n",
        " \n",
        "# Test the function\n",
        "convert_to_wav('call_1.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSL2oCjB4xWS",
        "outputId": "370fce48-e1bd-4627-e505-d9cd829cb3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting call_1.mp3 to call_1.wav...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Finding PyDub stats***\n",
        "\n",
        "You decide it'll be helpful to know the audio attributes of any given file easily. This will be especially helpful for finding out how many channels an audio file has or if the frame rate is adequate for transcription.\n",
        "\n",
        "Create `show_pydub_stats()` which takes a filename of an audio file as input. It then imports the audio as a **`PyDub`** **`AudioSegment`** instance and prints attributes such as number of channels, length and more.\n",
        "\n",
        "It then returns the **`AudioSegment`** instance so it can be used later on.\n",
        "\n",
        "We'll use our function on the newly converted `.wav` file, `call_1.wav`\n",
        "\n",
        "- Create an **`AudioSegment`** instance called `audio_segment` by importing the filename parameter.\n",
        "\n",
        "- Print the number of channels using the **`channels`** attribute.\n",
        "- Return the `audio_segment` variable.\n",
        "- Test the function on `\"call_1.wav\"`."
      ],
      "metadata": {
        "id": "O0F7p7zK5srs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_pydub_stats(filename):\n",
        "    \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
        "    # Create AudioSegment instance\n",
        "    audio_segment = AudioSegment.from_file(filename)\n",
        "    \n",
        "    # Print audio attributes and return AudioSegment instance\n",
        "    print(f\"Channels: {audio_segment.channels}\")\n",
        "    print(f\"Sample width: {audio_segment.sample_width}\")\n",
        "    print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
        "    print(f\"Frame width: {audio_segment.frame_width}\")\n",
        "    print(f\"Length (ms): {len(audio_segment)}\")\n",
        "    return audio_segment\n",
        "\n",
        "# Try the function\n",
        "call_1_audio_segment = show_pydub_stats('call_1.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTwYjWYD5X-l",
        "outputId": "154817cd-b17d-41b7-c220-ba57e0d67a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels: 1\n",
            "Sample width: 2\n",
            "Frame rate (sample rate): 32000\n",
            "Frame width: 2\n",
            "Length (ms): 54888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Transcribing audio with one line***\n",
        "\n",
        "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
        "\n",
        "Build `transcribe_audio()` which takes a `filename` as input, imports the `filename` using **`speech_recognition`**'s **`AudioFile`** class and then transcribes it using **`.recognize_google()`**.\n",
        "\n",
        "- Define a function called `transcribe_audio` which takes `filename` as an input parameter.\n",
        "- Setup a **`sr.Recognizer()`** instance as `recognizer`.\n",
        "- Use **`.recognize_google()`** to transcribe the audio data.\n",
        "- Pass the target call to the function."
      ],
      "metadata": {
        "id": "pBoMWrHe7GSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(filename):\n",
        "    \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
        "    # Setup a recognizer instance\n",
        "    recognizer = sr.Recognizer()\n",
        "    \n",
        "    # Import the audio file and convert to audio data\n",
        "    audio_file = sr.AudioFile(filename)\n",
        "    with audio_file as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "    \n",
        "    # Return the transcribed text\n",
        "    return recognizer.recognize_google(audio_data)\n",
        "\n",
        "# Test the function\n",
        "print(transcribe_audio('call_1.wav'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAgRrWVz6_ZY",
        "outputId": "573fca02-3c0d-4bc0-9121-57ebc12d08ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.72915477,\n",
            "                           'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'line my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Danielle this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'line my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John'}],\n",
            "    'final': True}\n",
            "hello welcome to Acme Studio support lawn my name is Daniel how can I best help you hey Daniel this is John Audrey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *ทำไม ถอดความออกมาได้สั้นนิดเดียว ???*\n",
        "\n",
        "\n",
        "```\n",
        "hello welcome to Acme studio support line my name is Daniel how can I best help you hey Daniel this is John I've recently bought a smart from you guys 3 weeks ago and I'm already having issues with it I know that's not good to hear John let's let's get your cell number and then we can we can set up a way to fix it for you one number for 17 varies how long do you reckon this is going to try our best to get the steel number will start up this support case I'm just really really really really I've been trying to contact past three 4 days now and I've been put on hold more than an hour and a half so I'm not really happy I kind of wanna get this issue 6 is f***** possible\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "t3ClGuB39H7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Using the helper functions you've built***\n",
        "\n",
        "Okay, now we've got some helper functions ready to go, it's time to put them to use!\n",
        "\n",
        "You'll first use `convert_to_wav()` to convert Acme's [`call_2.mp3`](https://assets.datacamp.com/production/repositories/4637/datasets/56f523fb855eaecc14a87c5619ec5e6e7c4490bc/ex4_call_1_stereo_formatted_mp3.mp3) to `.wav` format and save it as `call_2.wav`\n",
        "\n",
        "Using `show_pydub_stats()` you find `call_2.wav` has 2 channels so you decide to split them using **`PyDub`**'s **`split_to_mono()`**. Acme tells you the [customer channel](https://assets.datacamp.com/production/repositories/4637/datasets/03ace2e9b866aaa554c465d6698500aaf48599dc/ex4_call_1_channel_2_split.wav) is likely channel 2. So you export channel 2 using **`PyDub's .export()`**.\n",
        "\n",
        "Finally, you'll use `transcribe_audio()` to transcribe channel 2 only.\n",
        "\n",
        "- Convert the `.mp3` version of `call_2` to `.wav` and then check the stats of the `.wav` version.\n",
        "- Split `call_2` to mono and then export the second channel in `.wav` format.\n",
        "- Transcribe the audio of call 1's channel 2."
      ],
      "metadata": {
        "id": "oRZCXn2h-H89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert mp3 file to wav\n",
        "convert_to_wav(\"call_2.mp3\")\n",
        "\n",
        "# Check the stats of new file\n",
        "call_2 = show_pydub_stats(\"call_2.wav\")\n",
        "\n",
        "# Split call_1 to mono\n",
        "call_2_split = call_2.split_to_mono()\n",
        "\n",
        "# Export channel 2 (the customer channel)\n",
        "call_2_split[1].export(\"call_2_channel_2.wav\", format=\"wav\")\n",
        "\n",
        "# Transcribe the single channel\n",
        "print(transcribe_audio('call_1_channel_2.wav'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLplYe8X9lZ5",
        "outputId": "a72b458d-1a91-424e-8d48-7877a2da928b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting call_2.mp3 to call_2.wav...\n",
            "Channels: 2\n",
            "Sample width: 2\n",
            "Frame rate (sample rate): 32000\n",
            "Frame width: 4\n",
            "Length (ms): 54888\n",
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.72915483,\n",
            "                           'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'line my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'lawn my name is Daniel how can I '\n",
            "                                         'best help you hey Danielle this is '\n",
            "                                         'John Audrey'},\n",
            "                       {   'transcript': 'hello welcome to Acme Studio support '\n",
            "                                         'line my name is Daniel how can I '\n",
            "                                         'best help you hey Daniel this is '\n",
            "                                         'John'}],\n",
            "    'final': True}\n",
            "hello welcome to Acme Studio support lawn my name is Daniel how can I best help you hey Daniel this is John Audrey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *ยังคงถอดความได้ไม่ครบเหมือนเดิม ?*"
      ],
      "metadata": {
        "id": "7pAXl3atBePe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Analyzing sentiment of a phone call***\n",
        "\n",
        "Once you've transcribed the text from an audio file, it's possible to perform natural language processing on the text.\n",
        "\n",
        "Use NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner) to analyze the sentiment of the transcribed text of `call_2.wav`.\n",
        "\n",
        "To transcribe the text, we'll use the `transcribe_audio()` function we created earlier.\n",
        "\n",
        "Once we have the text, we'll use NLTK's **`SentimentIntensityAnalyzer()`** class to obtain a sentiment polarity score.\n",
        "\n",
        "**`.polarity_scores(text)`** returns a value for pos (positive), neu (neutral), neg (negative) and compound. Compound is a mixture of the other three values. The higher it is, the more positive the text. Lower means more negative.\n",
        "\n",
        "\n",
        "- Instantiate an instance of **`SentimentIntensityAnalyzer()`** and save it to the variable `sid`.\n",
        "- Transcribe the target call and save it to `call_2_text`.\n",
        "- Print the **`polarity_scores()`** of `call_2_text`."
      ],
      "metadata": {
        "id": "II_OscvGdLsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(filename):\n",
        "    \n",
        "    \"\"\"\n",
        "    Takes an audio filename as string and transcribes the text within it.\n",
        "    Note: For this exercise, the function has been mocked to prevent hitting the API usage limit.\n",
        "    \"\"\"\n",
        "\n",
        "    if type(filename) == str:\n",
        "        return \"hello my name is Daniel thank you for calling acne Studios how can I best help you a little bit more but I'm corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I'm actually walk straight past your shop yeah sure thing or thank you so it's good to hear you're enjoying it let me find out where the nearest store is for you\"\n",
        "    else:\n",
        "        raise TypeError(\"filename should be of type string, like: 'call_2.wav'\")\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create SentimentIntensityAnalyzer instance\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Let's try it on one of our phone calls\n",
        "call_2_text = transcribe_audio('call_2.wav')\n",
        "\n",
        "# Display text and sentiment polarity scores\n",
        "print(call_2_text)\n",
        "print(sid.polarity_scores(call_2_text))"
      ],
      "metadata": {
        "id": "7q37zMQB_rfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44bd0ea-f84a-4754-cc2f-ccd5a379682e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello my name is Daniel thank you for calling acne Studios how can I best help you a little bit more but I'm corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I'm actually walk straight past your shop yeah sure thing or thank you so it's good to hear you're enjoying it let me find out where the nearest store is for you\n",
            "{'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'compound': 0.9817}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Sentiment analysis on formatted text***\n",
        "\n",
        "Calculate the sentiment on the customer channel of `call_2.wav`.\n",
        "\n",
        "You've split the customer channel and saved it to `call_2_channel_2.wav`.\n",
        "\n",
        "But from your experience with sentiment analysis, you know it can change sentence to sentence.\n",
        "\n",
        "To calculate it sentence to sentence, you split the split using NLTK's **`sent_tokenize()`** module.\n",
        "\n",
        "But `transcribe_audio()` doesn't return sentences. To try sentiment anaylsis with sentences, you've tried a paid API service to get `call_2_channel_2_paid_api_text` which has sentences.\n",
        "\n",
        "- Transcribe the audio of `call_2_channel_2.wav` and find the sentiment scores.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xup4vLiIgJB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(filename):\n",
        "    \"\"\"\n",
        "    Takes an audio filename as string and transcribes the text within it.\n",
        "    Note: For this exercise, the function has been mocked to prevent hitting the API usage limit.\n",
        "    \"\"\"\n",
        "    if type(filename) == str:\n",
        "      return call_2_channel_2_text\n",
        "    else:\n",
        "      raise TypeError(\"filename should be of type string, like: 'call_2_channel_2.wav'\")\n",
        "\n",
        "call_2_channel_2_text = \"oh hi Daniel my name is Sally I recently purchased a smartphone from you guys and extremely happy with it I've just gotta issue not an issue but I've just got to learn a little bit more about the message bank on I have Google the location but I'm I'm finding it hard I thought you were on the corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I've actually walk straight past your shop\"\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create SentimentIntensityAnalyzer instance\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Transcribe customer channel of call 2\n",
        "call_2_channel_2_text = transcribe_audio('call_2_channel_2.wav')\n",
        "\n",
        "# Display text and sentiment polarity scores\n",
        "print(call_2_channel_2_text)\n",
        "print(sid.polarity_scores(call_2_channel_2_text))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRLo5ENnf_lb",
        "outputId": "f1fd386f-275b-418c-c838-f9d8c9690240"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oh hi Daniel my name is Sally I recently purchased a smartphone from you guys and extremely happy with it I've just gotta issue not an issue but I've just got to learn a little bit more about the message bank on I have Google the location but I'm I'm finding it hard I thought you were on the corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I've actually walk straight past your shop\n",
            "{'neg': 0.017, 'neu': 0.891, 'pos': 0.091, 'compound': 0.778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split `call_2_channel_2_text` into sentences and find the sentiment score of each sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "GEco_OONhSAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import sent_tokenize from nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create SentimentIntensityAnalyzer instance\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Split call 2 channel 2 into sentences and score each\n",
        "for sentence in sent_tokenize(call_2_channel_2_text):\n",
        "    print(sentence)\n",
        "    print(sid.polarity_scores(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpbjRhMMhSla",
        "outputId": "c4252a89-a99f-46cf-c3f2-12540b067dff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oh hi Daniel my name is Sally I recently purchased a smartphone from you guys and extremely happy with it I've just gotta issue not an issue but I've just got to learn a little bit more about the message bank on I have Google the location but I'm I'm finding it hard I thought you were on the corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I've actually walk straight past your shop\n",
            "{'neg': 0.017, 'neu': 0.891, 'pos': 0.091, 'compound': 0.778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split `call_2_channel_2_paid_api_text` into sentences and score the sentiment of each.\n"
      ],
      "metadata": {
        "id": "scyut3Wwhpf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_2_channel_2_paid_api_text = \"Hello and welcome to acme studios. My name's Daniel. How can I best help you? Hi Diane. This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible. Okay, Peter, sorry to hear about that. Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone? I can't quite hear you. Is this any better? Yeah, that's much better. And sorry, what was, what was it that you said when you first first started speaking?  So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line. This service is terrible. Okay. Well, what's your order id? I'll, uh, I'll start looking into that for you. Six, nine, eight, seven five. Okay. Thank you.\"\n",
        "\n",
        "# Import sent_tokenize from nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create SentimentIntensityAnalyzer instance\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Split channel 2 paid text into sentences and score each\n",
        "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
        "    print(sentence)\n",
        "    print(sid.polarity_scores(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoBgOu9ihjtK",
        "outputId": "82aaa26f-ffa5-479f-c46c-0eece59cd0a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello and welcome to acme studios.\n",
            "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
            "My name's Daniel.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "How can I best help you?\n",
            "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
            "Hi Diane.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible.\n",
            "{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'compound': -0.4767}\n",
            "Okay, Peter, sorry to hear about that.\n",
            "{'neg': 0.159, 'neu': 0.61, 'pos': 0.232, 'compound': 0.1531}\n",
            "Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone?\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "I can't quite hear you.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Is this any better?\n",
            "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
            "Yeah, that's much better.\n",
            "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
            "And sorry, what was, what was it that you said when you first first started speaking?\n",
            "{'neg': 0.08, 'neu': 0.92, 'pos': 0.0, 'compound': -0.0772}\n",
            "So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "This service is terrible.\n",
            "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
            "Okay.\n",
            "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
            "Well, what's your order id?\n",
            "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
            "I'll, uh, I'll start looking into that for you.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Six, nine, eight, seven five.\n",
            "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Okay.\n",
            "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
            "Thank you.\n",
            "{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Named entity recognition in spaCy***\n",
        "\n",
        "Named entities are real-world objects which have names, such as, cities, people, dates or times. We can use spaCy to find named entities in our transcribed text.\n",
        "\n",
        "Transcribe `call_4_channel_2.wav` using `transcribe_audio()` and then use spaCy's language model, **`en_core_web_sm`** to convert the transcribed text to a spaCy `doc`.\n",
        "\n",
        "Transforming text to a spaCy `doc` allows us to leverage spaCy's built-in features for analyzing text, such as, **`.text`** for tokens (single words), **`.sents`** for sentences and **`.ents`** for named entities.\n",
        "\n",
        "- Create a spaCy `doc` by passing the transcribed `call_4_channel_2_text` to **`nlp()`** and then check its type.\n",
        "\n",
        "- Create a spaCy `doc` with `call_4_channel_2_text` then print all the token text in it using the **`.text`** attribute.\n",
        "\n",
        "- Load the `\"en_core_web_sm\"` language model and then print the sentences in the doc using the **`.sents`** attribute.\n",
        "\n",
        "- Access the entities in the `doc` using **`.ents`** and then print the text of each."
      ],
      "metadata": {
        "id": "KzGqIblKgkaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "call_4_channel_2_text = \"oh hello Daniel my name is Ann and I've recently just purchased are a smartphone from you and I'm very happy with the product ID like to order another one for my friend who lives in Sydney and have it delivered I'm pretty sure it's model 315 I can check that for you and I'll give you my details arm if you would like to take my details and I I will also give you the address thank you excellent\"\n",
        "\n",
        "# Create a spaCy language model instance\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a spaCy doc with call 4 channel 2 text\n",
        "doc = nlp(call_4_channel_2_text)\n",
        "\n",
        "# Check the type of doc\n",
        "print(type(doc), '\\n')\n",
        "\n",
        "# Show tokens in doc\n",
        "for token in doc:\n",
        "    print(token.text, token.idx)\n",
        "print('\\n')\n",
        "\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)\n",
        "print('\\n')\n",
        "\n",
        "# Show named entities and their labels\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O74KFqw1iKbU",
        "outputId": "a826b50c-f93c-445a-8c46-95314633e13d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.doc.Doc'> \n",
            "\n",
            "oh 0\n",
            "hello 3\n",
            "Daniel 9\n",
            "my 16\n",
            "name 19\n",
            "is 24\n",
            "Ann 27\n",
            "and 31\n",
            "I 35\n",
            "'ve 36\n",
            "recently 40\n",
            "just 49\n",
            "purchased 54\n",
            "are 64\n",
            "a 68\n",
            "smartphone 70\n",
            "from 81\n",
            "you 86\n",
            "and 90\n",
            "I 94\n",
            "'m 95\n",
            "very 98\n",
            "happy 103\n",
            "with 109\n",
            "the 114\n",
            "product 118\n",
            "ID 126\n",
            "like 129\n",
            "to 134\n",
            "order 137\n",
            "another 143\n",
            "one 151\n",
            "for 155\n",
            "my 159\n",
            "friend 162\n",
            "who 169\n",
            "lives 173\n",
            "in 179\n",
            "Sydney 182\n",
            "and 189\n",
            "have 193\n",
            "it 198\n",
            "delivered 201\n",
            "I 211\n",
            "'m 212\n",
            "pretty 215\n",
            "sure 222\n",
            "it 227\n",
            "'s 229\n",
            "model 232\n",
            "315 238\n",
            "I 242\n",
            "can 244\n",
            "check 248\n",
            "that 254\n",
            "for 259\n",
            "you 263\n",
            "and 267\n",
            "I 271\n",
            "'ll 272\n",
            "give 276\n",
            "you 281\n",
            "my 285\n",
            "details 288\n",
            "arm 296\n",
            "if 300\n",
            "you 303\n",
            "would 307\n",
            "like 313\n",
            "to 318\n",
            "take 321\n",
            "my 326\n",
            "details 329\n",
            "and 337\n",
            "I 341\n",
            "I 343\n",
            "will 345\n",
            "also 350\n",
            "give 355\n",
            "you 360\n",
            "the 364\n",
            "address 368\n",
            "thank 376\n",
            "you 382\n",
            "excellent 386\n",
            "\n",
            "\n",
            "oh hello Daniel my name is Ann and I've recently just purchased are a smartphone from you\n",
            "and I'm very happy with the product ID like to order another one for my friend who lives in Sydney and have it delivered I'm pretty sure it's model 315 I can check that for you\n",
            "and I'll give you my details arm if you would like to take my details\n",
            "and I I will also give you the address thank you excellent\n",
            "\n",
            "\n",
            "Ann PERSON\n",
            "Sydney GPE\n",
            "315 CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Creating a custom named entity in spaCy***\n",
        "\n",
        "If spaCy's built-in named entities aren't enough, you can make your own using spaCy's **`EntityRuler()`** class.\n",
        "\n",
        "**`EntityRuler()`** allows you to create your own entities to add to a spaCy pipeline.\n",
        "\n",
        "You start by creating an instance of `EntityRuler()` and passing it the current pipeline, `nlp`.\n",
        "\n",
        "You can then call **`add_patterns()`** on the instance and pass it a dictionary of the text pattern you'd like to label with an entity.\n",
        "\n",
        "Once you've setup a pattern you can add it the nlp pipeline using add_pipe().\n",
        "\n",
        "Since Acme is a technology company, you decide to tag the pattern `\"smartphone\"` with the `\"PRODUCT\"` entity tag.\n",
        "\n",
        "spaCy has been imported and a `doc` already exists containing the transcribed text from `call_4_channel_2.wav`.\n",
        "\n",
        "\n",
        "- Import **`EntityRuler`** from `spacy.pipeline`.\n",
        "- Add `\"smartphone\"` as the value for the **`\"pattern\"`** key.\n",
        "- Add the **`EntityRuler()`** instance, ruler, to the `nlp` pipeline.\n",
        "- Print the entity attributes contained in `doc`."
      ],
      "metadata": {
        "id": "qMGSQkBckibE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import EntityRuler class\n",
        "from spacy.pipeline import EntityRuler\n",
        "from spacy.language import Language\n",
        "\n",
        "# Create EntityRuler instance\n",
        "ruler = EntityRuler(nlp)\n",
        "\n",
        "# Define pattern for new entity\n",
        "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": 'smartphone'}])\n",
        "\n",
        "# Update existing pipeline ในเวอร์ชัน 3 จะต้องใช้สตริง \"entity_ruler\" แทน  \n",
        "nlp.add_pipe('entity_ruler', before=\"ner\")\n",
        "\n",
        "# Test new entity\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMstmQKAjdmx",
        "outputId": "ffed21e8-86d4-4411-a8fd-51cb6c61b3e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ann PERSON\n",
            "Sydney GPE\n",
            "315 CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Naive Bayes Pipeline**\n",
        "\n"
      ],
      "metadata": {
        "id": "BbUiJMzczh_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text classifier pipeline\n",
        "\n",
        "text_classifier = Pipeline([(\"vectorizer\", CountVectorizer()),\n",
        "                            (\"tfidf\", TfidfTransformer()),\n",
        "                            (\"classifier\", MultinomialNB())])\n",
        "\n",
        "# Fit the classifier pipeline on the training data\n",
        "text_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and compare them to test labels\n",
        "predictions = text_classifier.predict(X_test)\n",
        "accuracy = 100 * np.mean(predictions == y_test.label)\n",
        "print(f\"The model is {accuracy:.2f}% accurate.\")"
      ],
      "metadata": {
        "id": "swUwbX0ZviDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Preparing audio files for text classification***\n",
        "\n",
        "Acme are very impressed with your work so far. So they've sent over two more folders of audio files.\n",
        "\n",
        "One folder is called `pre_purchase` and contains audio snippets from customers who are pre-purchase, like `pre_purchase_audio_25.mp3`.\n",
        "\n",
        "And the other is called `post_purchase` and contains audio snippets from customers who have made a purchase (post-purchase), like `post_purchase_audio_27.mp3`.\n",
        "\n",
        "Upon inspecting the files you find there's about 50 in each and they're in the `.mp3` format.\n",
        "\n",
        "Go through each folder and convert the audio files to `.wav` format using `convert_to_wav()` so you can transcribe them.\n",
        "\n",
        "\n",
        "- Convert the files in `pre_purchase` to `.wav` using `convert_to_wav()`.\n",
        "- Convert the files in `post_purchase` to `.wav` using `convert_to_wav()`."
      ],
      "metadata": {
        "id": "iOBSLlIq0Fn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_wav(filename):\n",
        "    \"\"\"\n",
        "    Converts a non .wav file to a .wav file.\n",
        "    Note: this function has been mocked to prevent memory issues with the DataCamp teach editor. The original can be found in a previous exercise.\n",
        "    \"\"\"\n",
        "    new_filename = filename.split(\".\")[0] + \".wav\"\n",
        "\n",
        "# Convert post purchase\n",
        "for file in post_purchase:\n",
        "    print(f\"Converting {file} to .wav...\")\n",
        "    convert_to_wav(file)\n",
        "\n",
        "# Convert pre purchase\n",
        "for file in pre_purchase:\n",
        "    print(f\"Converting {file} to .wav...\")\n",
        "    convert_to_wav(file)"
      ],
      "metadata": {
        "id": "-KgpU1DI05ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Transcribing phone call excerpts***\n",
        "\n",
        "Transcribe the audio files we converted to `.wav` format to text using `transcribe_audio()`.\n",
        "\n",
        "Since there's lots of them and there could be more, we'll build a function `create_test_list()` which takes a list of filenames of audio files as input and goes through each file transcribing the text.\n",
        "\n",
        "`create_test_list()` uses our `transcribe_audio()` function we created earlier and returns a list of strings containing the transcribed text from each audio file.\n",
        "\n",
        "`pre_purchase_wav_files` and `post_purchase_wav_files` are lists of audio snippet filenames.\n",
        "\n",
        "- Use `transcribe_audio()` to transcribe the current file to text and add it to the text list.\n",
        "- Return the text list."
      ],
      "metadata": {
        "id": "510BcqFt1qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = ['post_purchase_audio_1.wav']\n",
        "\n",
        "def transcribe_audio(file):\n",
        "  \"\"\"\n",
        "  Takes a .wav format audio file and transcribes it to text.\n",
        "  Note: For this exercise, this function has been mocked to prevent memory errors in the DataCamp teach editior.\n",
        "  \"\"\"\n",
        "  return 'hey man I just water product from you guys and I think is amazing but I leave a little help setting it up'\n",
        "\n",
        "def create_text_list(folder):\n",
        "  # Create empty list\n",
        "  text_list = []\n",
        "  \n",
        "  # Go through each file\n",
        "  for file in folder:\n",
        "    # Make sure the file is .wav\n",
        "    if file.endswith(\".wav\"):\n",
        "      print(f\"Transcribing file: {file}...\")\n",
        "      \n",
        "      # Transcribe audio and append text to list\n",
        "      text_list.append(transcribe_audio(file))   \n",
        "  return text_list\n",
        "\n",
        "create_text_list(folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwdCZWZ52EPI",
        "outputId": "0c1368f3-ba5e-4ba5-b6a5-3c4ee8bad83a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: post_purchase_audio_1.wav...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey man I just water product from you guys and I think is amazing but I leave a little help setting it up']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `create_text_list()` to transcribe all post and pre purchase audio snippets.\n",
        "- Check the first transcription of the post purchase text list."
      ],
      "metadata": {
        "id": "2Xd-MPWH2uQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe post and pre purchase text\n",
        "post_purchase_text = create_text_list(post_purchase_wav_files)\n",
        "pre_purchase_text = create_text_list(pre_purchase_wav_files)\n",
        "\n",
        "# Inspect the first transcription of post purchase\n",
        "print(post_purchase_text[0])"
      ],
      "metadata": {
        "id": "oK8fhAMY2Vxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Organizing transcribed phone call data***\n",
        "\n",
        "We're almost ready to build a text classifier. But right now, all of our transcribed text data is in two lists, `pre_purchase_text` and `post_purchase_text`.\n",
        "\n",
        "To organize it better for building a text classifier as well as for future use, we'll put it together into a pandas DataFrame.\n",
        "\n",
        "To start we'll `import pandas as pd` then we'll create a post purchase dataframe, `post_purchase_df` using **`pd.DataFrame()`**.\n",
        "\n",
        "We'll `pass pd.DataFrame()` a dictionary containing a `\"label\"` key with a value of `\"post_purchase\"` and a `\"text\"` key with a value of our `post_purchase_text list`.\n",
        "\n",
        "We'll do the same for `pre_purchase_df` except with `pre_purchase_text`.\n",
        "\n",
        "To have all the data in one place, we'll use **`pd.concat()`** and pass it the pre and post purchase DataFrames.\n",
        "\n",
        "- Create `post_purchase_df` using the `post_purchase_text` list.\n",
        "- Create `pre_purchase_df` using the `pre_purchase_text` list.\n",
        "- Combine the two DataFrames using **`pd.concat()`**."
      ],
      "metadata": {
        "id": "dXnfdFmA3gW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "post_purchase_text = ['hey man I just bought a product from you guys and I think is amazing but I leave a little help setting it up',\n",
        " 'these clothes I just bought from you guys too small is there any way I can change the size',\n",
        " \"I recently got these pair of shoes but they're too big can I change the size\",\n",
        " \"I bought a pair of pants from you guys but they're way too small\",\n",
        " \"I bought a pair of pants and they're the wrong colour is there any chance I can change that\",\n",
        " \"hey mate how you doing I'm just calling in regards the product that god it's faulty and doesn't work\",\n",
        " \"just wondering if there's any tutorials on how to set up my device I just received\",\n",
        " \"hey I'm just not happy with the product that you guys send me there any chance I can swap it out for another one\",\n",
        " 'I bought a pair of pants from you guys and they are just a bit too long do you guys do Hemi',\n",
        " 'is there anybody that can help me set up this product or any how to use',\n",
        " \"hey mate I just bought a product from you guys and I'm just unhappy with the pop the product can I return it\",\n",
        " \"just received the product from you guys and it didn't meet my expectations can I please get a refund\",\n",
        " \"what's the process I have to go through to send my product back for a swap\",\n",
        " \"hey mate how are you doing just wanting to know if there's any support I can get on this device how to set it up\",\n",
        " \"what's your refund policy on items that I've purchased from you guys\",\n",
        " \"hey how we doing I just put a cat from you guys and it's just the Wrong Colours is there any chance I can change that\",\n",
        " \"call me on to talk about a package I got yesterday it's I got it but I need to do I need some help with setting it up\",\n",
        " \"I got my order yesterday and the order number is 1863 3845 I'm just calling up to to check some more details on that\",\n",
        " 'I would have a couple of things from you guys the other day and two it two of them two of them and great and I love them but the other one is is not the right thing',\n",
        " \"yeah hello I'm just wondering if I can speak to someone about an order I received yesterday\",\n",
        " 'wrong package delivered',\n",
        " \"hey I ordered something yesterday and it arrived it arrived this morning but it seems like there's a few a few extra things in there that I didn't really order is there someone that I can talk to you to fix this up\",\n",
        " \"hey I bought something from your website the other day and it arrived but it's it's not the thing that I ordered is there someone I can talk to her to fix this up\",\n",
        " \"hello someone from your team delivered my package today but it's it's got a problem with it\",\n",
        " \"my shipment arrived this afternoon but it's wrong size is there anyone I can talk to you to change it\",\n",
        " 'I just bought a item from you guys and ID want to know if I can swap it for a different colour',\n",
        " \"hey I received my order but it's the wrong size can I get a refund please\",\n",
        " \"hey my order arrived today but it's it's there's a it's I don't think it's the one that I ordered I check the receipt and it doesnt match what what a right\",\n",
        " \"hey I'm calling up to to see if I can talk to someone to help with her a shipment that I received yesterday\",\n",
        " \"I just received this device and I'd love some supported to be able to set it up\",\n",
        " \"I just bought a product from you guys and I wouldn't want to know if I can send it back to get a colour change\",\n",
        " \"I purchase something from your online store yesterday but the receipt didn't come through can can I get another receipt emailed please\",\n",
        " 'the product arrived and there was a few things in the box but two of them the wrong is there someone I can talk to about fixing up my order',\n",
        " \"I'm just happy with the colour that I got from you guys so is there any chance I can change it for a different one\",\n",
        " \"a couple of days ago I got a message saying that my package have been delivered it wasn't delivered that day but it still hasn't arrived there someone I can talk to about my order\",\n",
        " \"my shipment arrived yesterday but it's not the right thing is there someone I can talk to you to fix it up\",\n",
        " \"my shipment arrived yesterday but it's not the right thing is there someone I can talk to you to fix it up\",\n",
        " \"my package was supposed to be delivered yesterday but it it didn't arrive is there someone I can talk to about my order\",\n",
        " \"my package was supposed to be delivered yesterday but it it didn't arrive is there someone I can talk to about my order\",\n",
        " \"I bought a hat from you guys and it's just too big is there anyway I can get it down size and what's your policies on that\",\n",
        " 'calling in regards to the order I just got would love some support',\n",
        " \"my order a 64321 arrived this morning but it's something wrong with it is there someone I can talk to to fix it\",\n",
        " \"yeah hello someone this morning delivered a package but I think it's I think it's not the right one that I ordered is there someone I can talk to you too to change it\",\n",
        " \"on the box that you sent me yesterday arrived but it's damaged the someone I can talk to her about replacement\",\n",
        " \"I've just bought a product can you guys and I want to know what your return keys and Caesar\",\n",
        " \"my order a 64321 arrived this morning but it's something wrong with it is there someone I can talk to to fix it\",\n",
        " \"hey my name is Daniel I received my shipment yesterday but it's wrong can I change it\",\n",
        " \"all the things I received the my order yesterday would damaged I'm not sure what happened to delivery is there someone that can give me a hand\",\n",
        " 'the shipment I received is wrong',\n",
        " \"yeah hey I need I need some help with her with an order that I ordered the other day it it came and it wasn't it wasn't correct\",\n",
        " \"yeah hello someone this morning delivered a package but I think it's I think it's not the right one that I ordered is there someone I can talk to you too to change it\",\n",
        " 'the shipment I received is wrong',\n",
        " \"yeah hello I'm just wondering if I can speak to someone about an order I received yesterday\",\n",
        " \"my shipment arrived this afternoon but it's wrong size is there anyone I can talk to you to change it\",\n",
        " \"all the things I received the my order yesterday would damaged I'm not sure what happened to delivery is there someone that can give me a hand\",\n",
        " 'hey mate the must have been a problem with the shipping because the product I just received from you is damaged',\n",
        " \"hey mate how you doing just calling in regards to the phone I just purchased from you guys faulty not working and now he's damaged on the way here\"]\n",
        "\n",
        "pre_purchase_text = ['yeah hi John just calling in regards to a recent order I just placed I found a cheaper product online and I was wondering if I could cancel that',\n",
        " \"I was looking online it says that you're only size is available a large and small I was wondering if you'll have any mediums in soon\",\n",
        " 'hi I was just wondering if you have the extra large tea and blue',\n",
        " 'yeah hey Steve just calling in regards to a recent order I just placed I was wondering if I could cancel that order',\n",
        " 'hi I just ordered a new phone and I was just wondering if I could cancel out order and organise a refund',\n",
        " 'hi I just ordered a new t-shirt and I was wondering if I could cancel an order and organise a refund',\n",
        " 'accidentally made some errors and order I recently just placed I was wondering if you could help me',\n",
        " \"I just placed an order online and I was just wondering when I'll get my confirmation email\",\n",
        " \"hey mate I just finished paying for my order and I was just wondering when I'm going to get that email to confirm it\",\n",
        " 'hey I was wondering if you know where my new phone is that I just recently ordered',\n",
        " 'do you currently offer any new promotions at the moment',\n",
        " \"hi I just pre-ordered the nudity and this is my order number but doctor I was just wondering if you know where abouts it isn't shipment\",\n",
        " 'your hi Jacob looking to make an order but just have a few questions regarding some products that you have online',\n",
        " 'hi I just recently placed an order with your company I was just wondering if you know the status of my shipment',\n",
        " \"Archie thank god I'm free been on hold for the last 30 minutes yeah got a couple of complaints made about this order I just posted\",\n",
        " \"hi just calling in regards to my order on November the 3rd I was just wondering when that's going to leave your office\",\n",
        " \"just looking to get some more information on the current promotions you're offering right now before I place my order\",\n",
        " \"hi I recently ordered a new phone and I'm just wondering where I could find my reference number for the delivery\",\n",
        " 'hey mate just looking to make some alterations to my order I just placed',\n",
        " 'hey just looking to place this order but I see that you have a promotion still running can you give me some more details behind this promotion',\n",
        " \"hi I placed an order a couple days ago and I was just wondering why my tracking number isn't working\",\n",
        " 'hi I just realised I ordered the wrong computer I was wondering if I could just cancel that and organise a refund',\n",
        " \"yeah I just placed an all this you guys and I was wondering if I could change a few things before it's shift out\",\n",
        " \"how's it going after I just placed an order with you guys and I accidentally sent it to the wrong address can you please help me change this\",\n",
        " \"hey Polly just looking to place an order but before I proceed I'm just wondering if this offer still stands\",\n",
        " 'yeah hi Tommy I just placed an order with you guys but I use the wrong payment processing method I was wondering if I could change that',\n",
        " 'hi Michael just looking to enquire about a few things before I placed an order I was wondering if you could help me',\n",
        " 'hi I saw your new phone on your website I was wondering if you have any setup tips for',\n",
        " \"I just ordered the new remote control car off you website I was just didn't see how many horsepower it has can you tell me\",\n",
        " 'hi just about to order these shoes online I was just wondering if you have any different sizes in store',\n",
        " 'I just placed an order and I was wondering if I could change my shipping time from standard business days to rush if possible',\n",
        " 'hey I just ordered the new phone and I was wondering if I could get airpods put into that order just before you guys send it',\n",
        " 'hi Jacob I just placed an order with you guys but I found the same product online it and other store for a cheaper price I was wondering if you could price match it or could I cancel this order',\n",
        " 'it says here you have the iPhone x l and X I was wondering if you still stock the iPhone 10',\n",
        " 'hey I was just looking online at your shoes and I was wondering if you have this brand in Pink',\n",
        " 'I just placed an order I was wondering how long shipping time would be expected to be',\n",
        " \"hey mate just have a few questions regarding the recent order I just posted it shows that it's coming from overseas however when I looked at the Australian soccer shop online it says that there's current stock in store for the Australian store\",\n",
        " 'hi I just ordered some shoes and I was just wondering if I could cancel that order and make a refund',\n",
        " 'hey I just ordered the blue and yellow shoes off your website and I was wondering if I could cancel that order and organise a refund',\n",
        " 'hey so I just placed an order with your company and I was just wondering where I can find my reference number',\n",
        " 'hey I was just wondering about the sizing on your shirts it says us as how does that relate to AUD',\n",
        " \"hi Tony I just placed an order I'm currently having a few problems I was wondering if you could help me\",\n",
        " 'yeah hi David I just placed an order online and I was wondering if I could make an alteration to that order before you send it off',\n",
        " 'hi I was just looking at finding a new phone I was wondering if you could recommend anything to me',\n",
        " 'I I just ordered the green and blue shoes off your website and I was wondering if I could add a shirt to my order before you send it']\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Make dataframes with the text\n",
        "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
        "                                 \"text\": post_purchase_text})\n",
        "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
        "                                \"text\": pre_purchase_text})\n",
        "\n",
        "# Combine DataFrames\n",
        "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
        "\n",
        "# Print the combined DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSfkh3VH4S8c",
        "outputId": "045f4ed9-2eff-4099-976f-073084dc2762"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           label                                               text\n",
            "0  post_purchase  hey man I just bought a product from you guys ...\n",
            "1  post_purchase  these clothes I just bought from you guys too ...\n",
            "2  post_purchase  I recently got these pair of shoes but they're...\n",
            "3  post_purchase  I bought a pair of pants from you guys but the...\n",
            "4  post_purchase  I bought a pair of pants and they're the wrong...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Create a spoken language text classifier***\n",
        "\n",
        "Now you've transcribed some customer call audio data, we'll build a model to classify whether the text from the customer call is `pre_purchase` or `post_purchase`.\n",
        "\n",
        "We've got 45 examples of `pre_purchase` calls and 57 examples of `post_purchase` calls.\n",
        "\n",
        "The data the model will train on is stored in `train_df` and the data the model will predict on is stored in `test_df`.\n",
        "\n",
        "Try printing the `.head()` of each of these to the console.\n",
        "\n",
        "We'll build an sklearn pipeline using **`CountVectorizer()`** and **`TfidfTransformer()`** to convert our text samples to numbers and then use a **`MultinomialNB()`** classifier to learn what category each sample belongs to.\n",
        "\n",
        "This model will work well on our small example here but for larger amounts of text, you may want to consider something more sophisticated.\n",
        "\n",
        "\n",
        "- Create `text_classifier` using **`CountVectorizer()`**, **`TfidfTransformer()`**, and **`MultinomialNB()`**.\n",
        "- Fit `text_classifier` on `train_df.text` and `train_df.label`.\n",
        "- Create predicted by calling **`predict()`** on `text_classifier` and passing it the text column of `test_df`.\n",
        "- Evaluate the model by seeing how predicted compares to the `test_df['label']`."
      ],
      "metadata": {
        "id": "Wj3k9HBQ5QeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('customer_call_transcriptions.csv')\n",
        "train_df = df.iloc[:81]\n",
        "test_df = df.iloc[81:]\n",
        "\n",
        "# Build the text_classifier as an sklearn pipeline\n",
        "text_classifier = Pipeline([('vectorizer', CountVectorizer()),\n",
        "                            ('tfidf', TfidfTransformer()),\n",
        "                            ('classifier', MultinomialNB())])\n",
        "\n",
        "# Fit the classifier pipeline on the training data\n",
        "text_classifier.fit(train_df['text'], train_df['label'])\n",
        "\n",
        "# Evaluate the MultinomialNB model\n",
        "predicted = text_classifier.predict(test_df['text'])\n",
        "accuracy = 100 * np.mean(predicted == test_df['label'])\n",
        "print(f'The model is {accuracy}% accurate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ojtRL9T5Mka",
        "outputId": "d58eb025-4caf-414a-aea3-9ef9a117f169"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is 90.47619047619048% accurate\n"
          ]
        }
      ]
    }
  ]
}